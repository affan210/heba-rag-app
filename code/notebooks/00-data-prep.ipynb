{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PDF Document \n",
    "\n",
    "We're going to pretend we're nutrition students at the University of Hawai'i, reading through the open-source PDF textbook [*Human Nutrition: 2020 Edition*](https://pressbooks.oer.hawaii.edu/humannutrition2/).\n",
    "\n",
    "There are several libraries to open PDFs with Python but I found that [PyMuPDF](https://github.com/pymupdf/pymupdf) works quite well in many cases.\n",
    "\n",
    "First we'll download the PDF if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File human-nutrition-text.pdf exists.\n"
     ]
    }
   ],
   "source": [
    "# Download PDF file\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Get PDF document\n",
    "pdf_path = \"human-nutrition-text.pdf\"\n",
    "\n",
    "# Download PDF if it doesn't already exist\n",
    "if not os.path.exists(pdf_path):\n",
    "  print(\"File doesn't exist, downloading...\")\n",
    "  # The URL of the PDF you want to download\n",
    "  url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
    "  # The local filename to save the downloaded file\n",
    "  filename = pdf_path\n",
    "  # Send a GET request to the URL\n",
    "  response = requests.get(url)\n",
    "  # Check if the request was successful\n",
    "  if response.status_code == 200:\n",
    "      # Open a file in binary write mode and save the content to it\n",
    "      with open(filename, \"wb\") as file:\n",
    "          file.write(response.content)\n",
    "      print(f\"The file has been downloaded and saved as {filename}\")\n",
    "  else:\n",
    "      print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "else:\n",
    "  print(f\"File {pdf_path} exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF acquired!\n",
    "\n",
    "We can import the pages of our PDF to text by first defining the PDF path and then opening and reading it with PyMuPDF (`import fitz`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9a62d5cd394bb194c37e7a5e81d54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': -41,\n",
       "  'page_char_count': 29,\n",
       "  'page_word_count': 4,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 7.25,\n",
       "  'text': 'Human Nutrition: 2020 Edition'},\n",
       " {'page_number': -40,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires !pip install PyMuPDF, see: https://github.com/pymupdf/pymupdf\n",
    "import fitz\n",
    "from tqdm.auto import tqdm # for progress bars, requires !pip install tqdm \n",
    "import random\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip() # note: this might be different for each doc (best to experiment)\n",
    "    # Other potential text formatting functions can go here\n",
    "    return cleaned_text\n",
    "\n",
    "# Open PDF and get lines/pages\n",
    "# Note: this only focuses on text, rather than images/figures etc\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Opens a PDF file, reads its text content page by page, and collects statistics.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The file path to the PDF document to be opened and read.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each containing the page number\n",
    "        (adjusted), character count, word count, sentence count, token count, and the extracted text\n",
    "        for each page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)  # open a document\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
    "        text = page.get_text()  # get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\"page_number\": page_number - 41,  # adjust page numbers since our PDF starts on page 42\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                                \"text\": text})\n",
    "    return pages_and_texts\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1091,\n",
       "  'page_char_count': 1086,\n",
       "  'page_word_count': 196,\n",
       "  'page_sentence_count_raw': 8,\n",
       "  'page_token_count': 271.5,\n",
       "  'text': 'Image by  Tomasz  Sienick / CC  BY- SA 3.0  Risk Factors for Osteoporosis  A risk factor is defined as a variable that is linked to an increased  probability of developing a disease or adverse outcome. Recall that  advanced age and being female increases the likelihood for  developing osteoporosis. These factors present risks that should  signal doctors and individuals to focus more attention on bone  health, especially when the risk factors exist in combination. This is  because not all risk factors for osteoporosis are out of your control.  Risk factors such as age, gender, and race are biological risk factors,  and are based on genetics that cannot be changed. By contrast,  there are other risk factors that can be modified, such as physical  activity, alcohol intake, and diet. The changeable risk factors for  osteoporosis provide a mechanism to improve bone health even  though some people may be genetically predisposed to the disease.    Physical Activity  Bone is a living tissue, like muscle, that reacts to exercise by gaining  Nutrition, Health and Disease  |  1091'},\n",
       " {'page_number': 101,\n",
       "  'page_char_count': 770,\n",
       "  'page_word_count': 138,\n",
       "  'page_sentence_count_raw': 6,\n",
       "  'page_token_count': 192.5,\n",
       "  'text': 'Bronchioles  lead to  alveolar sacs  in the  respiratory  zone, where  gas exchange  occurs.  includes the nose and its adjacent structures, the pharynx, the  larynx, the trachea, and the bronchi.  Respiratory Zone  In contrast to the conducting zone, the respiratory zone includes  structures that are directly involved in gas exchange. The  respiratory zone begins where the terminal bronchioles join a  respiratory bronchiole, the smallest type of bronchiole (Figure 2.16  “Respiratory Zone”), which then leads to an alveolar duct, opening  into a cluster of alveoli.  Figure 2.16 Respiratory Zone  Alveoli  An alveolar duct is a tube composed of smooth muscle and  connective tissue, which opens into a cluster of alveoli. An alveolus  The Respiratory System  |  101'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(pages_and_texts, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some stats on the text\n",
    "\n",
    "This means that the model has been trained in ingest and turn into embeddings texts with 384 tokens (1 token ~= 4 characters ~= 0.75 words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           199.50                    10.52   \n",
       "std         348.86           560.38            95.83                     6.55   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     5.00   \n",
       "50%         562.50          1231.50           216.00                    10.00   \n",
       "75%         864.25          1603.50           272.00                    15.00   \n",
       "max        1166.00          2308.00           430.00                    39.00   \n",
       "\n",
       "       page_token_count  \n",
       "count           1208.00  \n",
       "mean             287.00  \n",
       "std              140.10  \n",
       "min                0.00  \n",
       "25%              190.50  \n",
       "50%              307.88  \n",
       "75%              400.88  \n",
       "max              577.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further text processing (splitting pages into sentences)\n",
    "\n",
    "The ideal way of processing text before embedding it is still an active area of research.\n",
    "\n",
    "A simple method I've found helpful is to break the text into chunks of sentences.\n",
    "\n",
    "As in, chunk a page of text into groups of 5, 7, 10 or more sentences (these values are not set in stone and can be explored).\n",
    "\n",
    "But we want to follow the workflow of:\n",
    "\n",
    "`Ingest text -> split it into groups/chunks -> embed the groups/chunks -> use the embeddings`\n",
    "\n",
    "Some options for splitting text into sentences:\n",
    "\n",
    "1. Split into sentences with simple rules (e.g. split on \". \" with `text = text.split(\". \")`, like we did above).\n",
    "2. Split into sentences with a natural language processing (NLP) library such as [spaCy](https://spacy.io/) or [nltk](https://www.nltk.org/).\n",
    "\n",
    "Why split into sentences?\n",
    "\n",
    "* Easier to handle than larger pages of text (especially if pages are densely filled with text).\n",
    "* Can get specific and find out which group of sentences were used to help within a RAG pipeline.\n",
    "\n",
    "> **Resource:** See [spaCy install instructions](https://spacy.io/usage). \n",
    "\n",
    "Let's use spaCy to break our text into sentences since it's likely a bit more robust than just using `text.split(\". \")`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This another sentence.]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English # see https://spacy.io/usage for install instructions\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline, see https://spacy.io/api/sentencizer/ \n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Create a document instance as an example\n",
    "doc = nlp(\"This is a sentence. This another sentence.\")\n",
    "assert len(list(doc.sents)) == 2\n",
    "\n",
    "# Access the sentences of the document\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's run our small sentencizing pipeline on our pages of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6e7d3fa5df41bc941eb190138263b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    \n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    \n",
    "    # Count the sentences \n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 938,\n",
       "  'page_char_count': 1151,\n",
       "  'page_word_count': 199,\n",
       "  'page_sentence_count_raw': 9,\n",
       "  'page_token_count': 287.75,\n",
       "  'text': 'Image by  Cosmed /  CC BY-SA  3.0  Muscle Strength  Muscle strength is developed and maintained by weight or  resistance training that often is called anaerobic exercise. Anaerobic  exercise consists of short duration, high intensity movements that  rely on immediately available energy sources and require little or  no oxygen during the activity. This type of high intensity training  is used to build muscle strength by short, high intensity activities.  Building muscle mass is not just crucial for athletes and  bodybuilders—building muscle strength and endurance is important  for children, seniors, and everyone in between. The support that  your muscles provide allows you to work, play, and live more  efficiently. Strength training involves the use of resistance  machines, resistance bands, free weights, or other tools. However,  you do not need to pay for a gym membership or expensive  equipment to strengthen your muscles. Homemade weights, such as  plastic bottles filled with sand, can work just as well. You can also  use your own body weight and do push-ups, leg squats, abdominal  938  |  The Essential Elements of Physical Fitness',\n",
       "  'sentences': ['Image by  Cosmed /  CC BY-SA  3.0  Muscle Strength  Muscle strength is developed and maintained by weight or  resistance training that often is called anaerobic exercise.',\n",
       "   'Anaerobic  exercise consists of short duration, high intensity movements that  rely on immediately available energy sources and require little or  no oxygen during the activity.',\n",
       "   'This type of high intensity training  is used to build muscle strength by short, high intensity activities.',\n",
       "   ' Building muscle mass is not just crucial for athletes and  bodybuilders—building muscle strength and endurance is important  for children, seniors, and everyone in between.',\n",
       "   'The support that  your muscles provide allows you to work, play, and live more  efficiently.',\n",
       "   'Strength training involves the use of resistance  machines, resistance bands, free weights, or other tools.',\n",
       "   'However,  you do not need to pay for a gym membership or expensive  equipment to strengthen your muscles.',\n",
       "   'Homemade weights, such as  plastic bottles filled with sand, can work just as well.',\n",
       "   'You can also  use your own body weight and do push-ups, leg squats, abdominal  938  |  The Essential Elements of Physical Fitness'],\n",
       "  'page_sentence_count_spacy': 9}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an example\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           199.50                    10.52   \n",
       "std         348.86           560.38            95.83                     6.55   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     5.00   \n",
       "50%         562.50          1231.50           216.00                    10.00   \n",
       "75%         864.25          1603.50           272.00                    15.00   \n",
       "max        1166.00          2308.00           430.00                    39.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count           1208.00                    1208.00  \n",
       "mean             287.00                      10.32  \n",
       "std              140.10                       6.30  \n",
       "min                0.00                       0.00  \n",
       "25%              190.50                       5.00  \n",
       "50%              307.88                      10.00  \n",
       "75%              400.88                      15.00  \n",
       "max              577.00                      28.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking our sentences together\n",
    "\n",
    "Let's take a step to break down our list of sentences/text into smaller chunks.\n",
    "\n",
    "As you might've guessed, this process is referred to as **chunking**.\n",
    "\n",
    "Why do we do this?\n",
    "\n",
    "1. Easier to manage similar sized chunks of text.\n",
    "2. Don't overload the embedding models capacity for tokens (e.g. if an embedding model has a capacity of 384 tokens, there could be information loss if you try to embed a sequence of 400+ tokens).\n",
    "3. Our LLM context window (the amount of tokens an LLM can take in) may be limited and requires compute power so we want to make sure we're using it as well as possible.\n",
    "\n",
    "Something to note is that there are many different ways emerging for creating chunks of information/text.\n",
    "\n",
    "For now, we're going to keep it simple and break our pages of sentences into groups of 10 (this number is arbitrary and can be changed, I just picked it because it seemed to line up well with our embedding model capacity of 384).\n",
    "\n",
    "On average each of our pages has 10 sentences.\n",
    "\n",
    "And an average total of 287 tokens per page.\n",
    "\n",
    "So our groups of 10 sentences will also be ~287 tokens long.\n",
    "\n",
    "This gives us plenty of room for the text to embedded by our `all-mpnet-base-v2` model (it has a capacity of 384 tokens).\n",
    "\n",
    "To split our groups of sentences into chunks of 10 or less, let's create a function which accepts a list as input and recursively breaks into down into sublists of a specified size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4df6cdd0bfe40fb9625c0fb7a280e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10 \n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list, \n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                    slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 751,\n",
       "  'page_char_count': 1266,\n",
       "  'page_word_count': 240,\n",
       "  'page_sentence_count_raw': 16,\n",
       "  'page_token_count': 316.5,\n",
       "  'text': 'with 1 tsp. olive oil,  40     with 1 tsp. sesame seeds  18  ½ c. cooked wild rice  83     with ½ c. chopped kale  18  1 whole-wheat dinner roll  4     with 1 tsp. almond butter  33  691  (Total calories from all meals and  snacks = 1,814)  Discretionary calorie allowance: 186  (Total calories from all meals and snacks = 1,814)  Discretionary calorie allowance: 186  Healthy Eating Index  To assess whether the American diet is conforming to the Dietary  Guidelines, the Center for Nutrition Policy and Promotion (CNPP),  a division of the USDA, uses a standardized tool called the Healthy  Eating Index (HEI)2.  The first HEI was developed in 1995 and revised in 2006. This  tool is a simple scoring system of dietary components. The data for  scoring diets is taken from national surveys of particular population  subgroups, such as children from low-income families or Americans  over the age of sixty-five. Diets are broken down into several food  categories including milk, whole fruits, dark green and orange  vegetables, whole grains, and saturated fat, and then a score is  2. Healthy Eating Index. US Department of Agriculture.  http://www.cnpp.usda.gov/healthyeatingindex.htm.  Updated March 14, 2012. Accessed November 22, 2017.  MyPlate Planner  |  751',\n",
       "  'sentences': ['with 1 tsp.',\n",
       "   'olive oil,  40     with 1 tsp.',\n",
       "   'sesame seeds  18  ½ c. cooked wild rice  83     with ½ c. chopped kale  18  1 whole-wheat dinner roll  4     with 1 tsp.',\n",
       "   'almond butter  33  691  (Total calories from all meals and  snacks = 1,814)  Discretionary calorie allowance: 186  (Total calories from all meals and snacks = 1,814)  Discretionary calorie allowance: 186  Healthy Eating Index  To assess whether the American diet is conforming to the Dietary  Guidelines, the Center for Nutrition Policy and Promotion (CNPP),  a division of the USDA, uses a standardized tool called the Healthy  Eating Index (HEI)2.',\n",
       "   ' The first HEI was developed in 1995 and revised in 2006.',\n",
       "   'This  tool is a simple scoring system of dietary components.',\n",
       "   'The data for  scoring diets is taken from national surveys of particular population  subgroups, such as children from low-income families or Americans  over the age of sixty-five.',\n",
       "   'Diets are broken down into several food  categories including milk, whole fruits, dark green and orange  vegetables, whole grains, and saturated fat, and then a score is  2.',\n",
       "   'Healthy Eating Index.',\n",
       "   'US Department of Agriculture.',\n",
       "   ' http://www.cnpp.usda.gov/healthyeatingindex.htm.',\n",
       "   ' Updated March 14, 2012.',\n",
       "   'Accessed November 22, 2017.',\n",
       "   ' MyPlate Planner  |  751'],\n",
       "  'page_sentence_count_spacy': 14,\n",
       "  'sentence_chunks': [['with 1 tsp.',\n",
       "    'olive oil,  40     with 1 tsp.',\n",
       "    'sesame seeds  18  ½ c. cooked wild rice  83     with ½ c. chopped kale  18  1 whole-wheat dinner roll  4     with 1 tsp.',\n",
       "    'almond butter  33  691  (Total calories from all meals and  snacks = 1,814)  Discretionary calorie allowance: 186  (Total calories from all meals and snacks = 1,814)  Discretionary calorie allowance: 186  Healthy Eating Index  To assess whether the American diet is conforming to the Dietary  Guidelines, the Center for Nutrition Policy and Promotion (CNPP),  a division of the USDA, uses a standardized tool called the Healthy  Eating Index (HEI)2.',\n",
       "    ' The first HEI was developed in 1995 and revised in 2006.',\n",
       "    'This  tool is a simple scoring system of dietary components.',\n",
       "    'The data for  scoring diets is taken from national surveys of particular population  subgroups, such as children from low-income families or Americans  over the age of sixty-five.',\n",
       "    'Diets are broken down into several food  categories including milk, whole fruits, dark green and orange  vegetables, whole grains, and saturated fat, and then a score is  2.',\n",
       "    'Healthy Eating Index.',\n",
       "    'US Department of Agriculture.'],\n",
       "   [' http://www.cnpp.usda.gov/healthyeatingindex.htm.',\n",
       "    ' Updated March 14, 2012.',\n",
       "    'Accessed November 22, 2017.',\n",
       "    ' MyPlate Planner  |  751']],\n",
       "  'num_chunks': 2}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample an example from the group (note: many samples have only 1 chunk as they have <=10 sentences total)\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           199.50                    10.52   \n",
       "std         348.86           560.38            95.83                     6.55   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     5.00   \n",
       "50%         562.50          1231.50           216.00                    10.00   \n",
       "75%         864.25          1603.50           272.00                    15.00   \n",
       "max        1166.00          2308.00           430.00                    39.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count           1208.00                    1208.00     1208.00  \n",
       "mean             287.00                      10.32        1.53  \n",
       "std              140.10                       6.30        0.64  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              190.50                       5.00        1.00  \n",
       "50%              307.88                      10.00        1.00  \n",
       "75%              400.88                      15.00        2.00  \n",
       "max              577.00                      28.00        3.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to get stats\n",
    "pd.DataFrame(pages_and_texts).describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the average number of chunks is around 1.5, this is expected since many of our pages only contain an average of 10 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting each chunk into its own item\n",
    "\n",
    "We'd like to embed each chunk of sentences into its own numerical representation.\n",
    "\n",
    "So to keep things clean, let's create a new list of dictionaries each containing a single chunk of sentences with relative information such as page number as well statistics about each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578ed2cf0c9d46a4a6dc8d4c88555eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1843"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 114,\n",
       "  'sentence_chunk': '“Illu Urinary System” by Thstehle / Public Domain “The Bladder” by OpenStax College / CC BY 3.0 Figure 2.22 The Bladder 114 | The Urinary System',\n",
       "  'chunk_char_count': 144,\n",
       "  'chunk_word_count': 26,\n",
       "  'chunk_token_count': 36.0}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a random sample\n",
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!\n",
    "\n",
    "Now we've broken our whole textbook into chunks of 10 sentences or less as well as the page number they came from.\n",
    "\n",
    "This means we could reference a chunk of text and know its source.\n",
    "\n",
    "Let's get some stats about our chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>583.38</td>\n",
       "      <td>734.10</td>\n",
       "      <td>112.74</td>\n",
       "      <td>183.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>347.79</td>\n",
       "      <td>447.51</td>\n",
       "      <td>71.24</td>\n",
       "      <td>111.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>280.50</td>\n",
       "      <td>315.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>586.00</td>\n",
       "      <td>745.00</td>\n",
       "      <td>115.00</td>\n",
       "      <td>186.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>890.00</td>\n",
       "      <td>1118.00</td>\n",
       "      <td>173.00</td>\n",
       "      <td>279.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>1830.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>457.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count      1843.00           1843.00           1843.00            1843.00\n",
       "mean        583.38            734.10            112.74             183.52\n",
       "std         347.79            447.51             71.24             111.88\n",
       "min         -41.00             12.00              3.00               3.00\n",
       "25%         280.50            315.00             45.00              78.75\n",
       "50%         586.00            745.00            115.00             186.25\n",
       "75%         890.00           1118.00            173.00             279.50\n",
       "max        1166.00           1830.00            297.00             457.50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats about our chunks\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm looks like some of our chunks have quite a low token count.\n",
    "\n",
    "How about we check for samples with less than 30 tokens (about the length of a sentence) and see if they are worth keeping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 20.75 | Text: Centers for Disease Control and Prevention.http://www.cdc.gov/nutrition/ Iron | 661\n",
      "Chunk token count: 16.25 | Text: Updated January 2015. Accessed December 4, 2017. Middle Age | 917\n",
      "Chunk token count: 6.5 | Text: Fat-Soluble Vitamins | 537\n",
      "Chunk token count: 21.75 | Text: Advanced nutrition and human metabolism. Boston, MA: Cengage Learning. Molybdenum | 693\n",
      "Chunk token count: 22.75 | Text: Building a protein involves three steps: transcription, translation, Defining Protein | 369\n"
     ]
    }
   ],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like many of these are headers and footers of different pages.\n",
    "in case of retain some info. create overlapping chunks by adding + 1 in `num_sentence_chunk_size` in `slice_size` parameter of split_list in `Chunking our sentences together` Section \n",
    " \n",
    "They don't seem to offer too much information.\n",
    "\n",
    "Let's filter our DataFrame/list of dictionaries to only include chunks with over 30 tokens in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -39,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition UNIVERSITY OF HAWAI‘I AT MĀNOA FOOD SCIENCE AND HUMAN NUTRITION PROGRAM ALAN TITCHENAL, SKYLAR HARA, NOEMI ARCEO CAACBAY, WILLIAM MEINKE-LAU, YA-YUN YANG, MARIE KAINOA FIALKOWSKI REVILLA, JENNIFER DRAPER, GEMADY LANGFELDER, CHERYL GIBBY, CHYNA NICOLE CHUN, AND ALLISON CALABRESE',\n",
       "  'chunk_char_count': 308,\n",
       "  'chunk_word_count': 42,\n",
       "  'chunk_token_count': 77.0},\n",
       " {'page_number': -38,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition by University of Hawai‘i at Mānoa Food Science and Human Nutrition Program is licensed under a Creative Commons Attribution 4.0 International License, except where otherwise noted.',\n",
       "  'chunk_char_count': 210,\n",
       "  'chunk_word_count': 30,\n",
       "  'chunk_token_count': 52.5}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller chunks filtered!\n",
    "\n",
    "Time to embed our chunks of text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding our text chunks\n",
    "\n",
    "While humans understand text, machines understand numbers best.\n",
    "\n",
    "An [embedding](https://vickiboykis.com/what_are_embeddings/index.html) is a broad concept.\n",
    "\n",
    "But one of my favourite and simple definitions is \"a useful numerical representation\".\n",
    "\n",
    "The most powerful thing about modern embeddings is that they are *learned* representations.\n",
    "\n",
    "Meaning rather than directly mapping words/tokens/characters to numbers directly (e.g. `{\"a\": 0, \"b\": 1, \"c\": 3...}`), the numerical representation of tokens is learned by going through large corpuses of text and figuring out how different tokens relate to each other.\n",
    "\n",
    "Ideally, embeddings of text will mean that similar meaning texts have similar numerical representation.\n",
    "\n",
    "> **Note:** Most modern NLP models deal with \"tokens\" which can be considered as multiple different sizes and combinations of words and characters rather than always whole words or single characters. For example, the string `\"hello world!\"` gets mapped to the token values `{15339: b'hello', 1917: b' world', 0: b'!'}` using [Byte pair encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) (or BPE via OpenAI's [`tiktoken`](https://github.com/openai/tiktoken) library). Google has a tokenization library called [SentencePiece](https://github.com/google/sentencepiece).\n",
    "\n",
    "Our goal is to turn each of our chunks into a numerical representation (an embedding vector, where a vector is a sequence of numbers arranged in order).\n",
    "\n",
    "Once our text samples are in embedding vectors, us humans will no longer be able to understand them.\n",
    "\n",
    "However, we don't need to.\n",
    "\n",
    "The embedding vectors are for our computers to understand.\n",
    "\n",
    "We'll use our computers to find patterns in the embeddings and then we can use their text mappings to further our understanding.\n",
    "\n",
    "Enough talking, how about we import a text embedding model and see what an embedding looks like.\n",
    "\n",
    "To do so, we'll use the [`sentence-transformers`](https://www.sbert.net/docs/installation.html) library which contains many pre-trained embedding models.\n",
    "\n",
    "Specifically, we'll get the `all-mpnet-base-v2` model (you can see the model's intended use on the [Hugging Face model card](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#intended-uses))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\affan\\Programs\\miniconda3\\envs\\heba-rag\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\affan\\Programs\\miniconda3\\envs\\heba-rag\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The Sentences Transformers library provides an easy and open-source way to create embeddings.\n",
      "Embedding: [-2.07982659e-02  3.03164814e-02 -2.01217812e-02  6.86484948e-02\n",
      " -2.55256258e-02 -8.47686827e-03 -2.07231977e-04 -6.32377416e-02\n",
      "  2.81606596e-02 -3.33353728e-02  3.02633960e-02  5.30721396e-02\n",
      " -5.03526554e-02  2.62288544e-02  3.33313718e-02 -4.51577306e-02\n",
      "  3.63045074e-02 -1.37121335e-03 -1.20171625e-02  1.14947166e-02\n",
      "  5.04510924e-02  4.70856801e-02  2.11914051e-02  5.14606386e-02\n",
      " -2.03746390e-02 -3.58889215e-02 -6.67755026e-04 -2.94393897e-02\n",
      "  4.95859198e-02 -1.05639463e-02 -1.52014066e-02 -1.31760491e-03\n",
      "  4.48197499e-02  1.56023446e-02  8.60379259e-07 -1.21392065e-03\n",
      " -2.37978753e-02 -9.09372466e-04  7.34484568e-03 -2.53931386e-03\n",
      "  5.23370616e-02 -4.68043797e-02  1.66214872e-02  4.71579544e-02\n",
      " -4.15599197e-02  9.01963329e-04  3.60278040e-02  3.42213996e-02\n",
      "  9.68226939e-02  5.94829135e-02 -1.64984576e-02 -3.51249389e-02\n",
      "  5.92516316e-03 -7.07909290e-04 -2.41031516e-02  3.49741019e-02\n",
      " -2.94746719e-02  6.04263181e-03 -9.80649795e-03  2.83217784e-02\n",
      " -1.85375921e-02  3.63212973e-02  1.30292159e-02 -3.71232890e-02\n",
      "  5.27256541e-02 -1.19706960e-02 -7.18082935e-02  1.24431746e-02\n",
      " -6.70564827e-03  7.42154494e-02  1.16355829e-02 -1.74533855e-02\n",
      " -1.82405412e-02 -1.88931022e-02  2.82415003e-02  1.32829566e-02\n",
      " -3.51909883e-02  8.87301634e-04  5.79572171e-02  3.22093964e-02\n",
      " -3.48581048e-03  4.13768589e-02  1.44358343e-02 -3.28044444e-02\n",
      " -9.79089458e-03 -3.16492803e-02  4.23871055e-02 -4.70846258e-02\n",
      " -2.08936892e-02 -1.91249158e-02 -1.22627253e-02  1.01606240e-02\n",
      "  3.91921923e-02 -2.61896234e-02  1.09028090e-02  1.35723092e-02\n",
      " -5.79266995e-02 -3.21500041e-02 -5.75725455e-03 -2.43515912e-02\n",
      "  5.23416512e-02  5.46121364e-03 -2.30996106e-02  2.57176370e-03\n",
      " -6.63347021e-02  3.54125127e-02 -1.03907576e-02  2.25410163e-02\n",
      " -1.84573773e-02 -2.42007412e-02 -4.78365272e-02 -4.79220180e-03\n",
      " -5.34138307e-02  3.01790144e-02 -1.56130968e-02 -5.51477037e-02\n",
      " -3.91874313e-02  5.92152812e-02 -3.47646475e-02  9.68123320e-03\n",
      "  2.13415716e-02  2.30417028e-02  1.91712957e-02  2.77378410e-02\n",
      " -7.73503538e-03  1.04446011e-02 -2.67719496e-02 -2.40199957e-02\n",
      " -1.92290172e-02  3.91506357e-03 -2.54714936e-02  3.61943394e-02\n",
      "  5.12867384e-02 -8.41693301e-03 -3.13829966e-02  1.47483191e-02\n",
      "  2.13940218e-02 -3.84900980e-02  2.01945305e-02  1.20766303e-02\n",
      " -3.12067661e-03  7.84035400e-03  3.30337672e-03 -4.94357534e-02\n",
      "  5.83886951e-02  3.26138106e-03  4.84484900e-03 -4.50682342e-02\n",
      "  2.45682839e-02  3.55427973e-02 -5.32506146e-02  9.21152979e-02\n",
      "  2.04395074e-02 -3.36951762e-02 -6.19803406e-02 -2.11039279e-02\n",
      "  7.82358944e-02  5.11908121e-02  5.93170635e-02 -1.25148203e-04\n",
      "  4.96350378e-02 -1.55723114e-02 -3.35679366e-03  1.82016380e-02\n",
      " -2.73444150e-02 -1.08772144e-02  1.41476346e-02  1.09877810e-02\n",
      "  4.32555191e-03  8.23311210e-02 -9.85355233e-04  7.58791342e-02\n",
      "  9.44996625e-03  2.37687640e-02  1.61927715e-02  6.24993667e-02\n",
      "  4.75922376e-02 -3.92628461e-03  9.07524601e-02  4.49874513e-02\n",
      " -3.47131565e-02  2.14077104e-02 -3.35604250e-02  4.93849218e-02\n",
      "  1.08669335e-02  2.63447296e-02 -3.26089673e-02  8.00303891e-02\n",
      "  9.29766987e-03  7.16583710e-03 -2.79172324e-02 -3.06821074e-02\n",
      "  4.01062099e-03 -4.93906774e-02 -3.13767255e-03  4.00537737e-02\n",
      " -3.97855118e-02  5.48014268e-02  1.36393928e-05 -8.38373080e-02\n",
      " -1.21547394e-02  3.40949669e-02  3.22404434e-03  6.11845925e-02\n",
      "  5.60066998e-02  9.62870661e-03  2.54616570e-02 -4.64168973e-02\n",
      " -3.98901105e-02  7.68132210e-02  2.28408761e-02 -2.26568673e-02\n",
      " -1.91193204e-02 -6.53029233e-02  4.56781276e-02 -4.43655392e-03\n",
      "  1.49631826e-02 -2.15077810e-02  2.74249003e-03  1.90358497e-02\n",
      "  5.91888726e-02 -2.47569252e-02  3.66144851e-02  5.63083924e-02\n",
      " -8.86449311e-03 -1.74324419e-02 -1.03288831e-03  2.47666370e-02\n",
      "  1.30763389e-02  5.04632853e-02 -5.28497063e-03  5.92397377e-02\n",
      "  6.29906431e-02 -4.36783172e-02 -4.97830622e-02  5.56296632e-02\n",
      " -2.44854130e-02 -8.26755092e-02  2.04910394e-02 -1.06446266e-01\n",
      "  6.64842501e-03  2.97304541e-02 -2.36440338e-02 -8.84618331e-03\n",
      "  2.45560776e-03 -3.35234329e-02  7.52212927e-02 -5.89880086e-02\n",
      " -3.67808267e-02  3.41542885e-02  5.41131124e-02 -1.74904764e-02\n",
      "  1.33920489e-02  4.71682698e-02  1.46116382e-02 -2.12310925e-02\n",
      " -6.55338541e-02  1.23857884e-02  2.76075024e-02 -8.02161731e-03\n",
      " -4.59636338e-02 -8.22441746e-03  9.16956179e-03 -1.56399254e-02\n",
      "  7.54621299e-03  1.58311927e-03 -3.03958412e-02 -5.10671251e-02\n",
      "  1.96313988e-02  1.26263117e-02 -1.51736918e-03  2.02891491e-02\n",
      "  1.37817459e-02  1.49110677e-02  2.50766966e-02 -3.62870544e-02\n",
      "  1.08085480e-02  2.74132914e-03  1.81510691e-02  5.39872013e-02\n",
      " -4.74542193e-02 -4.28731218e-02 -2.89914273e-02  2.13235393e-02\n",
      " -3.85161154e-02  6.31922930e-02 -5.77976182e-02  3.77890025e-03\n",
      " -2.54394151e-02 -1.77256225e-04  9.08248406e-03  1.59095246e-02\n",
      "  4.11799848e-02 -3.94367501e-02 -9.64434445e-03  1.30791450e-02\n",
      "  6.87962621e-02  4.32192795e-02  7.53972621e-04  6.77741170e-02\n",
      "  4.93705757e-02 -3.47824022e-03 -1.06055075e-02  6.72491174e-03\n",
      " -1.39062181e-02  4.88276593e-02 -1.05735147e-02  3.50225274e-03\n",
      "  2.90225493e-03  2.40044072e-02  1.20271742e-02 -2.09797565e-02\n",
      " -2.39111949e-02  3.26579362e-02 -1.01328513e-03 -5.92755526e-03\n",
      " -7.40532205e-03  3.63145513e-03 -2.26698555e-02 -2.21241657e-02\n",
      "  3.86996344e-02  1.72321778e-02  3.85919921e-02 -5.04711531e-02\n",
      " -3.42145376e-02 -4.00443934e-02 -3.57910804e-02 -4.62561436e-02\n",
      "  6.70231953e-02 -4.61648917e-03 -3.29676294e-03  2.08444372e-02\n",
      " -5.14257606e-03 -5.00850081e-02  2.22504269e-02  4.66933548e-02\n",
      "  1.36208571e-02  1.77529901e-02  4.28079488e-03 -2.79332418e-02\n",
      " -1.93421189e-02 -3.87859792e-02 -3.09554413e-02 -6.64134324e-02\n",
      " -1.13433767e-02  1.64267402e-02  1.77629553e-02 -2.28225626e-03\n",
      " -3.30087170e-02 -1.36263226e-03 -2.17934456e-02 -2.67508309e-02\n",
      " -1.26375668e-02  1.61868671e-03 -4.95672449e-02  7.85446167e-02\n",
      "  4.10962850e-02  9.65921115e-03 -1.14643658e-02  1.68858806e-03\n",
      "  5.37663065e-02  2.05532415e-03 -4.11200225e-02  1.46330344e-02\n",
      " -3.75564247e-02 -3.35689522e-02  5.19258110e-03 -6.33088574e-02\n",
      "  3.32963057e-02  8.76116008e-03  1.33861240e-03 -3.95743083e-03\n",
      " -1.61677469e-02  8.26746672e-02  4.75945212e-02 -3.43055315e-02\n",
      "  2.50881128e-02 -3.50977369e-02  3.68657336e-02  4.12647799e-03\n",
      "  4.16018106e-02 -1.35181695e-01 -4.76338044e-02 -1.20025724e-02\n",
      " -3.48891690e-02  3.25455219e-02 -2.93577067e-03 -4.85055288e-03\n",
      " -1.04223706e-01  2.78610438e-02  1.41570345e-02  3.94395627e-02\n",
      " -3.88806835e-02 -1.42463753e-02 -5.19984104e-02  8.92732851e-03\n",
      " -1.99770723e-02 -2.51725167e-02 -3.41299661e-02  1.93041451e-02\n",
      " -5.20208143e-02 -6.72000498e-02 -9.46364645e-03 -1.25586556e-03\n",
      " -5.66048734e-02  2.62098592e-02  9.91585758e-03  4.38286513e-02\n",
      "  2.26642913e-03 -3.11895721e-02 -6.25467598e-02 -3.87793668e-02\n",
      " -6.83939531e-02  4.93721589e-02  5.85507751e-02 -4.08729464e-02\n",
      " -1.98638197e-02 -2.12634392e-02  4.98037525e-02 -4.51748818e-02\n",
      " -2.37141829e-02  2.32674759e-02  1.00594811e-01  9.87120252e-03\n",
      " -1.38015356e-02 -5.21041527e-02  9.08207987e-03  1.72427651e-02\n",
      "  5.91431409e-02  2.62336619e-02 -7.04641733e-03 -1.50032165e-02\n",
      " -3.76661122e-03  6.28259778e-03 -5.23981005e-02 -4.96638604e-02\n",
      "  3.06611042e-02 -3.33647477e-03  2.34911293e-02 -8.58830139e-02\n",
      " -4.62449044e-02  5.59701025e-02  3.09053663e-04  2.01729070e-02\n",
      " -2.98053515e-03  1.76646002e-02  1.54669620e-02 -7.41718039e-02\n",
      "  7.34994700e-03 -1.05015608e-02  2.45247204e-02  1.36879114e-02\n",
      " -1.17803710e-02  4.51545157e-02  3.29039581e-02 -3.50386696e-03\n",
      " -2.71314867e-02 -5.27363643e-02 -4.60164361e-02  2.22848877e-02\n",
      "  2.62271464e-02  5.56151941e-03  1.45789022e-02 -2.97145657e-02\n",
      "  3.57042663e-02  2.22534090e-02  3.89617048e-02 -7.92634487e-02\n",
      " -9.01089888e-03  2.19013114e-02 -5.49055124e-03  8.69954377e-03\n",
      "  4.33031060e-02 -2.12631524e-02  1.13291964e-02 -6.33699074e-02\n",
      "  3.63723524e-02  2.67442819e-02 -6.64252266e-02  1.70499403e-02\n",
      " -2.79691201e-02  2.36355281e-03 -1.81953032e-02  1.52955800e-02\n",
      " -8.50433577e-03  1.16647240e-02 -9.75922123e-02 -2.92093102e-02\n",
      " -5.42547554e-02  3.61234769e-02  3.25117521e-02  8.26975890e-03\n",
      " -2.96529412e-04  1.11556249e-02 -3.85188013e-02  2.36161277e-02\n",
      "  9.85919498e-03  5.73998615e-02  4.86061200e-02 -1.37579311e-02\n",
      " -6.19218871e-03  1.11973351e-02 -3.37175131e-02 -1.10515710e-02\n",
      " -7.08333850e-02 -1.01816524e-02 -3.66010927e-02 -1.55561082e-02\n",
      " -2.13110540e-02 -1.02760708e-02 -4.35733572e-02  5.55186532e-02\n",
      " -3.76548283e-02  5.29252850e-02 -3.45223919e-02 -2.43007415e-03\n",
      "  7.25553557e-02  4.45070770e-03  4.71417755e-02 -9.43884067e-03\n",
      " -1.98978949e-02  5.71899973e-02  8.60541239e-02 -5.25058024e-02\n",
      " -1.39549635e-02  1.17372982e-02  1.33974049e-02 -4.73052897e-02\n",
      " -5.41673563e-02  4.62725908e-02 -2.58969814e-02  1.51415281e-02\n",
      "  3.38945203e-02 -3.78262647e-03 -5.76043501e-02 -1.60082169e-02\n",
      "  2.42739096e-02  3.37360911e-02 -1.96821094e-02 -2.53464058e-02\n",
      " -4.75617014e-02 -5.68755232e-02 -2.28194296e-02  3.83187607e-02\n",
      " -1.78331137e-02  1.35964155e-02  7.85964832e-04  9.74010490e-03\n",
      "  3.34298797e-02 -2.60134041e-02 -7.38566602e-03  3.56451236e-02\n",
      " -2.68532317e-02 -7.53624886e-02 -2.66983714e-02 -4.46457493e-33\n",
      " -3.31646614e-02  1.41703654e-02 -3.92909683e-02 -3.46318670e-02\n",
      " -5.88671770e-03 -1.18212253e-02  1.53951626e-02  1.18473545e-02\n",
      "  1.07757207e-02  3.62140015e-02  7.87953008e-03 -2.31845621e-02\n",
      "  1.07623013e-02  1.72346253e-02  9.54188232e-04  2.83640493e-02\n",
      "  2.37419419e-02 -1.48058496e-02  1.24196592e-03  3.52355139e-03\n",
      "  2.33735740e-02  5.58307916e-02  5.38327917e-02 -3.74079086e-02\n",
      " -2.11805683e-02  1.52736204e-04 -7.27787009e-03  5.50555438e-03\n",
      "  3.05823591e-02  4.54632863e-02 -3.35786976e-02  3.16142403e-02\n",
      " -2.56394641e-03  3.96355428e-02 -1.47573687e-02  5.67167774e-02\n",
      " -5.62787578e-02 -5.04599465e-03  3.56154703e-02 -2.76198722e-02\n",
      " -2.32292097e-02 -4.63291854e-02 -3.70919332e-02 -4.23188992e-02\n",
      "  3.70306931e-02  7.88719207e-03  3.85175906e-02  1.74776453e-03\n",
      "  5.62758604e-03  6.18109154e-03 -6.90268725e-02 -9.42962244e-03\n",
      " -7.74675515e-03  1.68350060e-02  1.22767808e-02  2.26406604e-02\n",
      "  1.21008838e-02  1.11743705e-02  1.21539095e-02 -1.16862440e-02\n",
      " -4.41612564e-02  2.30047237e-02  2.20672432e-02 -5.87504506e-02\n",
      " -3.96428145e-02  6.83135241e-02 -3.29948068e-02 -3.66774984e-02\n",
      " -3.53654884e-02  1.76184736e-02  6.95639057e-03  5.92693314e-02\n",
      "  4.12156284e-02  7.98109397e-02 -5.36563387e-03  1.14238672e-02\n",
      " -2.96388492e-02 -1.15411580e-02  2.22812276e-02  7.93182291e-03\n",
      "  2.60356069e-02  1.28212320e-02  1.71345659e-02 -6.90188166e-03\n",
      " -1.07603110e-02  1.35714673e-02 -9.90774250e-04 -6.16075546e-02\n",
      "  4.40513864e-02 -8.26595584e-04 -2.78340913e-02 -1.23619344e-02\n",
      "  1.34629849e-02 -3.85745503e-02  1.08704716e-03  2.18712334e-02\n",
      " -3.32398526e-02  1.84616037e-02 -5.10112615e-03  3.74665186e-02\n",
      " -3.67545476e-03 -2.19246540e-02 -4.96481359e-03 -9.59841255e-03\n",
      "  2.33591367e-02  1.04876747e-02  4.38722111e-02 -1.51424101e-02\n",
      " -6.30308986e-02  8.23258236e-03 -1.09130694e-02 -4.06409428e-02\n",
      " -6.21691234e-02  2.21326314e-02 -2.71434430e-02  4.05539498e-02\n",
      " -8.09448585e-03 -1.76415546e-03  3.01526953e-02 -5.42262895e-03\n",
      " -4.69822101e-02 -1.73768830e-02  4.11630943e-02  3.20634879e-02\n",
      " -2.22944226e-02 -1.58162061e-02 -4.50720638e-02  5.69486283e-02\n",
      "  4.71595936e-02 -5.78058399e-02  1.32474992e-02 -4.71291412e-03\n",
      "  1.66824478e-07  4.81090434e-02  5.03628291e-02  5.45263365e-02\n",
      "  2.07568500e-02 -1.19080376e-02 -6.37493096e-03  5.26363729e-03\n",
      "  7.21949786e-02 -2.21762843e-02  2.20103040e-02 -9.90466913e-04\n",
      " -1.37163969e-02  6.89206133e-03  2.46912874e-02 -1.39462054e-01\n",
      "  2.56981817e-03 -4.64826524e-02 -4.04967293e-02 -6.08555488e-02\n",
      " -1.53213423e-02  1.36129886e-01  9.45034921e-02  4.25741449e-02\n",
      "  4.67131175e-02 -2.30677910e-02 -1.20966164e-02  3.86673249e-02\n",
      "  2.11644126e-03 -2.51473431e-02 -1.15076266e-02 -3.46506126e-02\n",
      " -2.29533464e-02 -6.33848133e-03 -3.05175819e-02 -1.56236561e-02\n",
      "  1.39514199e-02  3.27482994e-04  2.00320664e-03  4.15104255e-03\n",
      " -2.22924929e-02 -3.62589806e-02 -2.36579571e-02 -1.87817421e-02\n",
      " -1.96289551e-02  4.52126078e-02 -8.12568665e-02 -2.14568954e-02\n",
      " -4.41543497e-02 -2.68475674e-02  2.01974437e-02  2.82990164e-03\n",
      " -1.95011385e-02 -3.45331058e-02  2.26913672e-02  3.78325954e-02\n",
      " -1.02543952e-02 -2.19759485e-03 -8.96744430e-02 -4.50031310e-02\n",
      "  8.09703581e-03 -2.05805469e-02 -2.02998836e-02 -2.09922288e-02\n",
      " -1.79404691e-02  5.81897311e-02 -7.63652520e-03  1.50847333e-02\n",
      "  1.78279790e-34  4.86179441e-02  4.22228314e-02  4.71595563e-02\n",
      "  5.89047372e-02  3.99785154e-02 -5.27071729e-02  1.56905279e-02\n",
      " -5.25092415e-04  1.13651818e-02 -6.56410530e-02 -2.20849104e-02]\n",
      "\n",
      "Sentence: Sentences can be embedded one by one or as a list of strings.\n",
      "Embedding: [ 4.31718007e-02 -5.38702235e-02 -3.78044471e-02  4.27236110e-02\n",
      " -2.35408843e-02  3.44860889e-02  2.89586838e-02  1.92814029e-03\n",
      "  2.41733436e-02 -3.17012854e-02  7.32856169e-02  1.25590470e-02\n",
      "  3.64620537e-02 -2.05251444e-02  2.81973705e-02 -6.87328726e-02\n",
      "  4.22231480e-02  9.31756571e-04  3.54035422e-02  1.41787594e-02\n",
      "  7.83994235e-03  2.31179055e-02 -4.84733190e-03  1.07173705e-02\n",
      "  4.39488376e-03  5.47801005e-03 -3.80338766e-02 -3.05490079e-03\n",
      "  5.72229782e-03 -6.78214282e-02 -4.88007739e-02 -1.45032313e-02\n",
      "  6.68013189e-03 -7.17479587e-02  1.64644814e-06  1.07564256e-02\n",
      " -3.60922888e-02 -2.37056874e-02 -5.22791892e-02  3.46110500e-02\n",
      " -5.42173767e-03  1.62611585e-02  1.96564645e-02  2.25395877e-02\n",
      " -2.25997041e-03  4.06341925e-02  8.17157254e-02  2.48179697e-02\n",
      "  5.31884991e-02  7.82714933e-02 -1.91813763e-02 -1.94087308e-02\n",
      " -2.62805019e-02 -2.44082734e-02  5.49405813e-02  1.90319046e-02\n",
      "  1.60811376e-02 -2.68895179e-02 -8.24694242e-03  7.33444989e-02\n",
      "  1.00123333e-02  2.93315668e-02  3.42860492e-03 -2.13270225e-02\n",
      " -1.62441027e-03 -5.56257227e-03 -7.64879957e-02 -5.85450605e-02\n",
      " -2.82272063e-02  7.51845352e-03  7.11226016e-02  1.95455155e-03\n",
      "  5.45929652e-03  3.22319800e-03  5.12800068e-02 -3.54105830e-02\n",
      " -5.03608398e-02  4.70519289e-02  5.15478803e-03  1.52287120e-02\n",
      " -1.06680254e-02  3.16298679e-02 -9.09038074e-03 -4.01327722e-02\n",
      " -4.35236059e-02 -1.94969699e-02  1.65604670e-02 -4.71168645e-02\n",
      " -3.92091647e-02 -3.07757035e-02 -2.94167381e-02 -4.20826636e-02\n",
      "  2.27072462e-03 -2.78329402e-02  1.69421937e-02  7.74499448e-03\n",
      " -5.23742214e-02 -4.50040139e-02  3.83605063e-02 -4.90786731e-02\n",
      "  5.06618991e-02  1.01615479e-02 -1.25021413e-02 -4.64556180e-03\n",
      " -1.54539756e-02  1.58862285e-02  1.18370494e-02 -3.59232686e-02\n",
      " -7.76225626e-02  3.43358517e-02 -2.14710049e-02 -6.86098561e-02\n",
      " -5.46236373e-02  7.83901662e-02 -3.00702248e-02 -3.37550417e-02\n",
      " -4.04998623e-02  4.80515659e-02  9.53901280e-03  2.31399592e-02\n",
      " -8.16114917e-02 -6.51697069e-03  1.54213132e-02  7.04257637e-02\n",
      " -1.25069125e-02 -2.48267166e-02 -1.71328597e-02  6.13109674e-03\n",
      "  5.44412695e-02 -1.40565997e-02 -6.24515535e-03  3.65788043e-02\n",
      "  7.36230612e-02 -6.05681958e-03 -3.61630805e-02 -1.42203458e-03\n",
      "  4.43166010e-02 -3.14512383e-03  3.18767652e-02 -1.30948173e-02\n",
      " -3.69524434e-02 -4.98027727e-03  1.30018208e-03 -2.05213483e-02\n",
      "  2.06277799e-02  5.93871204e-03 -3.07166716e-03 -3.97513062e-02\n",
      "  4.29890044e-02  6.49802908e-02 -6.76022619e-02  5.41655794e-02\n",
      "  1.52561406e-03 -3.72908972e-02 -4.02427129e-02 -2.28772499e-02\n",
      "  1.31769791e-01  4.87873517e-03  1.39471041e-02  4.92435768e-02\n",
      "  2.49219183e-02 -8.76092073e-03 -5.38767874e-03 -2.65596043e-02\n",
      " -1.19766267e-02 -2.32006963e-02 -2.67433897e-02  5.66911278e-03\n",
      "  2.21722256e-02  4.67294045e-02 -5.78487664e-02  8.22120756e-02\n",
      " -3.36835627e-03  8.09647739e-02  1.41423093e-02  1.02393068e-01\n",
      " -5.76834660e-03 -1.15877520e-02  4.90584970e-02  5.87829724e-02\n",
      "  6.50030673e-02  4.74621579e-02 -2.89464146e-02 -1.76583801e-03\n",
      "  3.32561173e-02  2.91198269e-02  6.03811182e-02  3.73491814e-04\n",
      "  1.06576430e-02 -5.96284606e-02 -7.28601664e-02  2.95080114e-02\n",
      "  9.54464078e-03 -2.71542482e-02 -5.63305095e-02  9.66745371e-04\n",
      " -4.77729291e-02  4.67576943e-02  4.87256376e-03 -6.57519326e-02\n",
      " -1.42248245e-02  3.99872810e-02 -1.09797176e-02  7.68941641e-02\n",
      " -4.00004089e-02  2.96826493e-02  2.81303488e-02 -5.55424988e-02\n",
      "  6.31261151e-03  5.00450023e-02  1.89884286e-02  5.38683608e-02\n",
      " -1.95981823e-02  1.08601125e-02  1.64150260e-02  1.44135160e-02\n",
      "  1.71448886e-02  2.17624959e-02 -4.98863086e-02  1.56105030e-02\n",
      "  4.83739562e-03  1.87053420e-02 -3.18547548e-03  2.66863219e-02\n",
      "  5.55552766e-02 -4.88006137e-02 -3.02929152e-02  2.52110157e-02\n",
      "  1.07264761e-02  1.88270658e-02 -1.50687862e-02  3.43832076e-02\n",
      "  4.15125005e-02  1.37789138e-02 -5.54848649e-02  1.43848537e-02\n",
      " -5.88139407e-02 -6.01677075e-02  2.69856397e-02 -5.46129756e-02\n",
      "  8.14637356e-03 -1.17758438e-02  1.57442875e-02  1.43903506e-03\n",
      " -2.64554713e-02 -4.48876619e-02  4.39732485e-02 -1.06190542e-04\n",
      " -2.25906093e-02  3.00296787e-02  1.97440311e-02  7.44077330e-03\n",
      " -1.93789657e-02  8.09799321e-03  4.34859283e-02 -1.08602260e-04\n",
      " -3.77225801e-02  2.67196074e-02 -4.63157594e-02 -1.53400609e-03\n",
      "  8.05313140e-03 -4.30900827e-02 -2.13848799e-02  1.20185362e-02\n",
      "  8.41399655e-03  2.48270738e-03 -3.09566874e-02 -9.05277580e-02\n",
      " -4.76693623e-02  1.22606410e-02 -1.36467041e-02 -2.63655167e-02\n",
      " -7.65552605e-03  8.72379169e-03  2.65725125e-02  8.40033579e-04\n",
      " -5.55928471e-03 -9.29539837e-03  3.19337174e-02  5.94646595e-02\n",
      "  1.83205586e-02 -7.56546333e-02 -5.59388958e-02 -1.20870871e-02\n",
      " -3.16260904e-02  3.62187102e-02  7.53612118e-03 -6.15654141e-02\n",
      " -2.30459236e-02 -3.51668312e-03  1.23332087e-02 -9.67638381e-03\n",
      "  4.96861860e-02 -8.42256472e-02  1.52395982e-02 -1.82445366e-02\n",
      "  7.70462230e-02  9.28717777e-02  4.03724536e-02  1.11732617e-01\n",
      " -1.03270384e-02 -2.54558176e-02  2.13153828e-02 -1.16185274e-03\n",
      "  2.82600988e-03  5.06967194e-02 -3.13697159e-02 -8.14272836e-03\n",
      "  1.38387615e-02  4.66889516e-02  5.09670526e-02  3.77154276e-02\n",
      " -2.94988398e-02  3.60631905e-02 -2.61163921e-03  2.72273785e-04\n",
      " -6.71807006e-02 -6.54026195e-02 -3.43590789e-02  1.91067606e-02\n",
      "  4.13294137e-02 -1.10970605e-02  4.51951809e-02 -5.93565293e-02\n",
      "  1.06963683e-02 -1.82230007e-02 -5.65814339e-02  1.20386770e-02\n",
      "  4.44773845e-02  1.87050272e-02  1.63810048e-02  5.51150627e-02\n",
      " -2.23332252e-02  2.12861802e-02 -1.20339915e-02  3.26753296e-02\n",
      "  1.47004519e-02 -8.16684403e-03  1.12905130e-02 -3.00620534e-02\n",
      " -2.34345850e-02 -2.68646013e-02 -1.28719024e-03 -7.67189711e-02\n",
      "  2.22609169e-03 -5.89476526e-03  2.63103731e-02  2.07128585e-03\n",
      " -6.91152066e-02 -1.43791949e-02  2.68788394e-02 -3.51539850e-02\n",
      " -2.69611962e-02  2.54717190e-03 -6.48881719e-02  3.18728201e-02\n",
      "  1.70126744e-02 -4.54004109e-02 -1.80616137e-02 -1.61116086e-02\n",
      "  5.70773855e-02 -2.78272666e-03 -6.45585582e-02  7.86597952e-02\n",
      "  2.29075383e-02  6.81842258e-03 -9.11740866e-03 -2.27726232e-02\n",
      " -4.76526655e-02  4.88430783e-02 -2.09892020e-02 -2.43693721e-02\n",
      " -5.01208566e-03  6.70253858e-02  6.91372762e-03  2.25842874e-02\n",
      "  2.51125190e-02 -6.92508463e-03  8.59399140e-03  2.38977261e-02\n",
      "  3.29738446e-02 -1.05310552e-01  1.22094816e-02 -1.22263590e-02\n",
      " -5.73768765e-02  1.84311885e-02  2.97158323e-02 -6.09429218e-02\n",
      " -6.55256137e-02  3.55713181e-02  5.64321270e-03  3.34645808e-03\n",
      " -3.59686613e-02 -8.83417577e-03 -6.97895288e-02  6.89778998e-02\n",
      " -4.88214986e-03  2.23995019e-02 -3.16053517e-02 -7.41184130e-03\n",
      "  3.19351107e-02 -5.18788658e-02  2.11601593e-02 -5.03340475e-02\n",
      "  9.10577830e-03  2.13354379e-02  1.66838095e-02  3.49020176e-02\n",
      " -6.38499856e-02 -6.75625214e-03 -1.27405245e-02 -4.63366657e-02\n",
      " -1.14779910e-02  2.08778381e-02  2.44822353e-02  3.66461603e-03\n",
      " -2.86096637e-03  2.29390264e-02  2.13746037e-02 -3.48900966e-02\n",
      " -3.00388299e-02  4.78870384e-02  5.83370887e-02 -9.70497541e-03\n",
      "  1.38234757e-02 -3.27485874e-02 -8.11490347e-04  9.54227149e-03\n",
      "  1.20401243e-02  1.97230112e-02 -4.74844564e-04 -1.39226019e-02\n",
      " -5.21070473e-02 -1.75592490e-02 -5.41698448e-02 -1.17969960e-02\n",
      " -1.71030425e-02 -3.50195579e-02  3.38661559e-02 -6.76587224e-02\n",
      " -2.27607042e-02  1.95607003e-02  5.50249256e-02  1.22029008e-02\n",
      " -1.75168319e-03  7.22444244e-03  1.16350027e-02 -1.61907952e-02\n",
      " -3.37755270e-02  3.22626792e-02 -2.03813873e-02 -2.33859122e-02\n",
      " -1.29991891e-02 -1.66799147e-02  1.03070838e-02 -1.46030225e-02\n",
      " -7.79070929e-02 -8.25811997e-02 -3.38809825e-02  3.81114408e-02\n",
      "  7.86004029e-03  2.41454989e-02 -2.75715068e-02  1.30867055e-02\n",
      " -7.88593292e-03  1.78651046e-02  5.37323244e-02 -3.01823691e-02\n",
      "  1.69455204e-02  1.19571509e-02  3.52563744e-04  4.90209162e-02\n",
      " -8.57210904e-03  1.71269802e-03  4.83877258e-03 -4.10081148e-02\n",
      " -4.68121171e-02 -2.32557859e-03 -5.16776219e-02  3.10030393e-02\n",
      "  1.60961710e-02 -1.00803478e-02 -3.72481742e-03 -3.53388079e-02\n",
      "  2.95961536e-02  2.89097093e-02 -7.59911910e-02 -5.02981059e-02\n",
      " -2.11783722e-02  3.20462324e-02 -3.84538770e-02  2.45103128e-02\n",
      " -2.04188116e-02  6.02111639e-03 -9.81937069e-03  3.74777950e-02\n",
      "  3.40838991e-02  1.28864367e-02  5.67342602e-02 -8.09703991e-02\n",
      " -8.93610064e-03  1.33352568e-02 -2.51565911e-02  2.58415542e-03\n",
      " -6.51802942e-02  1.34400092e-02 -2.04682425e-02  6.53379736e-03\n",
      "  4.56973305e-03  1.99271366e-02 -6.07340336e-02  1.40691549e-02\n",
      " -5.75333908e-02  9.79803037e-03  3.55393291e-02 -2.45283507e-02\n",
      " -4.73315502e-03 -2.77493205e-02  2.34282669e-02 -8.76055637e-05\n",
      "  7.30441324e-03  1.42028732e-02  4.92807291e-02 -3.16540599e-02\n",
      " -1.34901870e-02  3.08487695e-02  2.80402061e-02 -4.33068909e-02\n",
      " -4.42284197e-02  3.80739272e-02  9.48013039e-05 -4.34896611e-02\n",
      "  1.43868020e-02  2.44325050e-03 -4.84073423e-02  1.08955456e-02\n",
      " -9.87488125e-03  4.59295325e-02  3.96379530e-02 -2.60117352e-02\n",
      "  2.48134509e-02 -5.37149534e-02  5.62824830e-02  8.81360285e-03\n",
      "  5.25076985e-02 -1.47371134e-02 -1.74381100e-02  3.45084257e-02\n",
      "  3.75523455e-02 -4.70167547e-02 -1.94911249e-02  3.82631943e-02\n",
      " -5.67595884e-02 -1.78610662e-03  2.33404450e-02 -5.88216234e-33\n",
      " -4.87188324e-02 -2.76265685e-02 -3.38240452e-02  2.66188290e-02\n",
      " -3.39276791e-02 -8.49192869e-03 -1.91250239e-02  3.00251897e-02\n",
      "  3.40781994e-02  5.11157587e-02 -1.92479789e-02  2.85642613e-02\n",
      "  3.66040245e-02  1.68858599e-02  4.77257818e-02  1.23801855e-02\n",
      "  2.14844272e-02  4.93616040e-04  1.21273994e-02 -5.82144074e-02\n",
      "  1.62954498e-02 -7.14262854e-03  4.80091870e-02  2.51190495e-02\n",
      "  4.60097566e-02 -2.29840558e-02 -2.05696393e-02 -3.22232582e-03\n",
      "  4.00091782e-02  3.52310389e-02 -3.43153961e-02  2.75629316e-03\n",
      " -1.25138648e-02  1.97686311e-02  5.53489942e-03  1.03744566e-01\n",
      "  5.77611336e-03 -5.65426573e-02  4.19558473e-02 -3.78830321e-02\n",
      " -3.93443145e-02 -6.24309592e-02 -2.24397634e-03 -5.46548814e-02\n",
      "  4.56134565e-02 -5.69246151e-03  3.38916853e-02 -1.44447759e-02\n",
      "  2.72106007e-03  1.11191999e-02 -5.00661060e-02 -1.61127076e-02\n",
      "  1.72823085e-03  6.88878447e-02  1.16493357e-02  2.83170901e-02\n",
      "  6.97192224e-03  2.68372092e-02 -7.72085087e-03  2.16828119e-02\n",
      "  1.15182800e-02  8.72832090e-02 -6.27270248e-03 -6.44473359e-02\n",
      " -1.58233717e-02  4.03268337e-02 -1.69728752e-02 -1.61188487e-02\n",
      " -3.75576764e-02  7.02938512e-02 -3.30486707e-02  4.66324240e-02\n",
      "  1.18028112e-02  6.51075318e-02 -1.16979545e-02 -8.28344002e-03\n",
      " -5.46905249e-02 -2.00226493e-02  8.42678128e-04 -8.19524471e-03\n",
      "  2.08356716e-02  1.37454523e-02 -1.29922421e-03 -3.94575447e-02\n",
      " -2.00184770e-02 -1.53721236e-02  1.17271794e-02 -4.40111272e-02\n",
      "  5.39267659e-02 -2.33011022e-02 -2.24211123e-02 -3.65214795e-03\n",
      "  2.92213447e-02  7.56439567e-03 -2.90923342e-02  4.01518010e-02\n",
      " -2.00853217e-02 -1.79860834e-03 -1.26236202e-02  2.51076780e-02\n",
      " -4.69285361e-02 -3.08554582e-02 -3.63335334e-04  6.01789355e-03\n",
      "  3.97508852e-02  1.38547802e-02  2.49774437e-02  1.76976379e-02\n",
      " -9.31572989e-02 -9.83688701e-03  8.44924524e-03 -1.95391010e-02\n",
      " -3.26569490e-02  5.13742305e-03  5.80931688e-03  2.08537001e-02\n",
      " -5.97832585e-03  5.86810298e-02 -1.49496421e-02 -5.72965518e-02\n",
      " -5.98235196e-03  1.95203908e-03  2.72976933e-03  6.06996333e-03\n",
      " -2.00525317e-02 -1.31688192e-02 -4.06229049e-02  5.68997227e-02\n",
      "  4.44968864e-02 -1.24308169e-02  1.96967777e-02  3.80979180e-02\n",
      "  2.30237632e-07  1.10575026e-02  4.79512922e-02  6.18298240e-02\n",
      "  4.40278538e-02  6.17665658e-03  2.58290558e-03  3.38913836e-02\n",
      " -5.32938028e-03 -2.59283353e-02 -1.26144085e-02  2.46495251e-02\n",
      " -1.68774324e-03  1.17902795e-03  2.40443405e-02 -9.77309421e-02\n",
      "  1.97367352e-02 -5.52920550e-02 -6.17424697e-02 -4.87151481e-02\n",
      "  1.11088646e-03  1.18732080e-01  8.13258216e-02  3.32448930e-02\n",
      "  4.38327082e-02 -2.49559432e-02 -3.59626785e-02  1.66319627e-02\n",
      "  5.93764475e-03 -1.43972300e-02  4.46708594e-03 -6.01986386e-02\n",
      " -5.65911531e-02 -8.21540412e-03  5.83060132e-03 -1.69482306e-02\n",
      "  9.58633795e-03  1.46733671e-02  5.05845733e-02  3.06891389e-02\n",
      "  6.60468638e-02 -2.56551839e-02 -2.78858412e-02 -3.19173411e-02\n",
      " -3.39236371e-02  1.49903139e-02 -3.03336121e-02 -6.06495142e-03\n",
      " -4.81772283e-03  1.72137059e-02 -8.23370740e-03  1.55547727e-02\n",
      "  2.69106571e-02  5.44308871e-03 -1.06899263e-02 -7.82141276e-03\n",
      " -4.44506966e-02  2.55874153e-02 -5.74760549e-02 -2.05443203e-02\n",
      " -3.07849851e-02 -1.57854948e-02 -7.07538659e-03 -4.21312302e-02\n",
      "  3.79933976e-02  6.27765507e-02 -7.67791551e-03 -3.18353400e-02\n",
      "  1.99277769e-34  1.04834242e-02 -3.39326672e-02  3.93821225e-02\n",
      "  5.53065650e-02  9.42169223e-03  1.09728407e-02 -4.91939299e-02\n",
      "  2.95024235e-02 -8.85373447e-03 -5.96248806e-02 -2.37825383e-02]\n",
      "\n",
      "Sentence: Embeddings are one of the most powerful concepts in machine learning!\n",
      "Embedding: [-2.98611671e-02 -1.37522072e-02 -4.75402139e-02  2.72126608e-02\n",
      "  3.40053849e-02  3.16465795e-02  4.26964015e-02  3.29798833e-03\n",
      "  4.35718037e-02  2.53837034e-02  3.02528720e-02  3.21130790e-02\n",
      " -3.99912819e-02  1.28761679e-02  6.70219585e-02 -7.92899728e-02\n",
      "  4.68772016e-02  2.40266807e-02 -2.07997989e-02 -1.07433451e-02\n",
      " -1.19410707e-02 -5.39291166e-02  4.21055444e-02  2.23588459e-02\n",
      " -2.98949610e-02  8.35979823e-03  1.58385336e-02 -4.80236076e-02\n",
      "  1.88438187e-03 -1.67521238e-02 -2.15628576e-02 -3.88488472e-02\n",
      "  3.06274127e-02  4.20526490e-02  1.69483337e-06 -1.86928976e-02\n",
      " -1.24558769e-02  1.32129062e-02 -4.89039570e-02  1.34746181e-02\n",
      "  2.28873137e-02  8.81785713e-03  8.64931382e-03 -2.00949777e-02\n",
      " -3.15217711e-02 -2.53433194e-02  7.57318363e-02  3.62446830e-02\n",
      "  1.25290249e-02  3.09694801e-02  4.50759614e-03 -3.50042358e-02\n",
      " -4.42454388e-04 -9.76647064e-03  6.04545325e-02  4.03472446e-02\n",
      "  1.10734953e-02  6.56200480e-03 -5.84594253e-03  3.79784917e-03\n",
      " -4.46914658e-02  1.76405236e-02  2.45916992e-02 -3.60041601e-03\n",
      "  1.02473356e-01  3.73758785e-02  6.13311911e-03 -2.24676747e-02\n",
      "  1.46482643e-02  5.00536375e-02 -2.29907185e-02  1.12924762e-02\n",
      " -3.10552269e-02 -1.49509087e-02 -2.53131217e-03  3.20945606e-02\n",
      " -4.67056185e-02 -4.85886782e-02  2.98306234e-02  6.44215569e-02\n",
      " -3.12613212e-02  3.57407033e-02  4.16526832e-02 -5.52517585e-02\n",
      " -8.74624029e-03 -2.18630210e-02 -1.12744207e-02 -2.14436520e-02\n",
      " -1.32823642e-02 -2.04865951e-02 -1.00576412e-02  3.54764089e-02\n",
      " -7.47611048e-03 -3.70188132e-02  5.77893294e-02 -2.18168981e-02\n",
      "  4.36223578e-03  2.04380360e-02  3.36814895e-02 -4.92800958e-02\n",
      "  4.82793376e-02 -1.81000168e-03 -1.05118826e-02  4.13323231e-02\n",
      " -6.79833964e-02  1.75715741e-02 -4.43412773e-02  9.90843400e-03\n",
      " -3.81809510e-02  1.10827619e-02 -5.07280305e-02 -2.17451137e-02\n",
      " -1.03836246e-02  4.60333191e-02  1.55862439e-02 -4.21366915e-02\n",
      " -2.72146296e-02  3.22819091e-02 -4.24739160e-02  2.71207299e-02\n",
      " -7.41061792e-02  4.20107432e-02  2.02438049e-02  7.31811225e-02\n",
      " -8.97695310e-03 -2.31160372e-02 -3.93559337e-02 -1.46008618e-02\n",
      " -3.30910496e-02  1.12239495e-02  2.58568744e-03 -4.36852220e-03\n",
      "  1.85855608e-02  2.69934665e-02 -1.67215243e-02  3.69569771e-02\n",
      "  4.44488674e-02 -2.21723374e-02  6.72960887e-03  1.22935213e-02\n",
      "  1.71758514e-02 -2.36476702e-03  3.72263603e-02 -2.22870521e-02\n",
      "  2.94603072e-02 -2.33691353e-02  5.38466033e-03 -3.06582004e-02\n",
      " -2.38920152e-02 -2.63614506e-02 -2.01788843e-02  1.11245595e-01\n",
      " -1.99836344e-02 -3.54030356e-02  3.84143926e-02  2.53069531e-02\n",
      "  1.99551415e-02  5.53518422e-02 -1.99333020e-02 -2.16720859e-03\n",
      "  4.91092764e-02 -4.03530560e-02 -1.16977161e-02 -5.33112884e-02\n",
      "  8.29589833e-03 -5.08251600e-02 -2.65504103e-02 -1.53243141e-02\n",
      "  5.78818237e-03  2.46578432e-03 -3.44449952e-02 -1.85130117e-03\n",
      " -3.95730473e-02 -2.71690842e-02  4.93568517e-02  8.38369057e-02\n",
      "  5.43492213e-02  8.22261497e-02  1.23894280e-02 -4.79795970e-03\n",
      "  7.77399691e-04  2.98486799e-02 -1.85583867e-02  5.98795414e-02\n",
      " -6.82795839e-03  9.78138181e-04  2.85485331e-02 -7.64621561e-03\n",
      " -1.86620336e-02 -2.69287359e-02 -2.90332641e-02 -1.37871867e-02\n",
      " -2.57598516e-03 -2.20173597e-02 -1.70821398e-02 -3.81842814e-02\n",
      "  2.21505556e-02 -3.59233879e-02 -1.19439727e-02 -3.18307653e-02\n",
      " -4.80800867e-02  9.77634545e-03 -1.04858109e-03  4.15370762e-02\n",
      " -1.10974330e-02 -4.72830646e-02  1.90984514e-02 -5.31177148e-02\n",
      "  2.11325418e-02 -2.53068237e-03  5.61054945e-02 -1.33795571e-02\n",
      " -5.95863955e-03 -1.20308101e-02  4.63929847e-02 -2.81908978e-02\n",
      "  2.25355253e-02 -2.50472687e-03 -3.52452919e-02  2.55495496e-02\n",
      "  9.10396408e-03  3.25215072e-03  2.55971355e-03 -1.25624202e-02\n",
      " -3.51496637e-02 -4.28946353e-02 -2.32333434e-03  2.41021160e-02\n",
      " -5.16836392e-03  1.68740172e-02  5.52642951e-03  2.36791801e-02\n",
      "  5.65164723e-02 -3.47868949e-02 -6.34518191e-02 -7.45625608e-03\n",
      " -1.78448558e-02  5.35897799e-02  2.67291646e-02 -8.74199420e-02\n",
      "  1.04196370e-02 -4.13958827e-04 -3.04448232e-03  9.14243236e-03\n",
      "  2.91530304e-02 -5.81831411e-02  6.83463439e-02 -4.08618189e-02\n",
      " -9.09785088e-03 -3.40770558e-02  3.52411680e-02 -1.02628171e-02\n",
      " -5.72484976e-04 -2.73450371e-03  1.59635581e-02  4.49063955e-03\n",
      " -2.09051967e-02  3.02769709e-02  2.46119276e-02 -1.44068161e-02\n",
      "  1.73269249e-02  1.99040351e-03  4.23051901e-02 -2.39176676e-02\n",
      " -3.25547233e-02 -1.45939989e-02  3.95100862e-02 -6.04650341e-02\n",
      " -3.02065760e-02  1.67189520e-02 -2.26817001e-02 -2.61954740e-02\n",
      " -5.51319532e-02  1.44908400e-02 -1.99246183e-02  3.99748143e-03\n",
      "  3.12609933e-02 -4.90727611e-02 -9.49781155e-04  5.39497472e-02\n",
      " -9.10083018e-03 -2.69486085e-02 -3.63158509e-02 -1.38436826e-02\n",
      " -4.45622168e-02  5.49359173e-02  2.17596581e-03  2.23440723e-03\n",
      " -5.23013715e-03 -1.47894062e-02  3.60592045e-02  1.45263430e-02\n",
      "  8.39191489e-03 -6.10360727e-02 -7.89954048e-03 -2.98293401e-03\n",
      "  3.56564810e-03  8.33992139e-02 -2.61215530e-02  8.06721747e-02\n",
      "  3.63053917e-03  1.69974770e-02  2.58604232e-02  1.09442463e-03\n",
      " -4.57063578e-02  5.55678457e-02  2.00643428e-02  4.76660989e-02\n",
      " -4.91053015e-02 -1.86081231e-02  3.34404819e-02 -2.57310439e-02\n",
      " -3.16365343e-03  7.21443817e-02 -1.61519498e-02 -1.33933192e-02\n",
      " -6.06293902e-02 -2.82187182e-02 -8.91926698e-03 -2.71173660e-03\n",
      "  8.04916490e-03 -4.95209284e-02  7.89434686e-02  2.76427884e-02\n",
      " -5.42583503e-03 -3.06723593e-03 -4.11826968e-02  1.39171705e-02\n",
      "  3.04253194e-02  1.02856327e-02  1.06679099e-02 -5.56554459e-02\n",
      " -1.75083131e-02  2.03868672e-02  8.43311008e-03  3.82470898e-02\n",
      " -3.89099680e-02 -1.61303058e-02  3.18059511e-02 -7.32969791e-02\n",
      " -1.76502261e-02 -4.79874238e-02 -5.55042028e-02 -5.00752870e-03\n",
      "  4.46808961e-04  3.57332900e-02 -8.24704417e-04 -3.34324576e-02\n",
      " -3.32416594e-02 -2.46460028e-02  2.15332173e-02  3.90861882e-03\n",
      "  2.53471341e-02  6.02992577e-03 -7.81606045e-03  1.23765571e-02\n",
      " -1.71039384e-02  2.68102791e-02  2.83673126e-03 -1.27643626e-02\n",
      "  1.00510910e-01  1.03580523e-02 -3.55143100e-02  1.56616662e-02\n",
      " -9.85949710e-02  4.58441637e-02 -3.15230973e-02 -2.35781316e-02\n",
      " -2.78350860e-02 -7.75794833e-05 -2.82363072e-02 -1.92918703e-02\n",
      "  1.87389962e-02  5.71940988e-02  2.56911758e-02 -3.20030116e-02\n",
      "  1.99073870e-02 -3.15820202e-02 -4.02061827e-02  5.77630512e-02\n",
      "  1.72974169e-02 -5.37014194e-02 -1.25325732e-02 -1.45484386e-02\n",
      " -5.76174594e-02  1.09727858e-02 -2.04728339e-02  2.85541117e-02\n",
      " -5.04399501e-02  4.36991267e-02  1.75711121e-02 -1.02343885e-02\n",
      " -9.69771892e-02 -2.99995188e-02 -2.86679305e-02  2.24936754e-02\n",
      " -1.68121587e-02 -1.43673718e-02 -8.79589282e-03 -1.69043839e-02\n",
      "  2.41558366e-02 -6.53192550e-02 -4.10799719e-02 -2.34059058e-02\n",
      " -6.76064789e-02 -1.55690797e-02  3.62358019e-02  7.83160180e-02\n",
      " -4.97517139e-02 -7.08548352e-02 -5.01179025e-02 -8.56420840e-04\n",
      "  5.44898864e-03  4.34699235e-03  9.88052934e-02 -2.16415487e-02\n",
      " -1.87750813e-02  1.15070017e-02  2.63996348e-02  1.65235754e-02\n",
      " -2.24057492e-02 -4.31826673e-02  1.31803930e-01 -2.97034606e-02\n",
      "  2.65934132e-02 -1.38888601e-02 -1.67003945e-02  3.44146043e-02\n",
      " -8.94357357e-03  6.16001152e-02 -3.42303067e-02  2.46420363e-03\n",
      " -8.14089272e-03  5.80325760e-02  5.24208434e-02 -1.53281419e-02\n",
      "  4.01383005e-02  1.51407979e-02 -3.01466952e-03 -4.97021340e-02\n",
      " -4.24298318e-03  5.77288605e-02  3.17874104e-02  4.74008210e-02\n",
      "  2.95218192e-02 -1.50122838e-02 -2.47945543e-02 -7.11502135e-02\n",
      "  2.06847657e-02  3.11487317e-02 -5.86068537e-03  1.62787270e-02\n",
      " -3.93682271e-02  5.46505786e-02  3.26594673e-02 -1.87021773e-02\n",
      " -9.79863331e-02  4.33767261e-03 -5.58157414e-02 -1.34620843e-02\n",
      "  2.88453978e-02  1.58748217e-02 -3.32564414e-02  1.44415873e-03\n",
      " -5.51108122e-02  8.24674219e-02  2.38845963e-02 -2.04837695e-02\n",
      " -4.78586927e-03  3.78722847e-02 -4.87563089e-02  3.44646946e-02\n",
      "  1.10358177e-02  1.12450356e-02  1.33262742e-02 -3.46375331e-02\n",
      " -6.92220852e-02  7.30125280e-03 -6.57013617e-03  1.73203219e-02\n",
      "  5.23056835e-03  4.48132157e-02  3.89853418e-02 -1.99273936e-02\n",
      " -1.80920567e-02  3.25937495e-02 -2.02026051e-02  4.86206787e-04\n",
      " -8.88757128e-03 -1.91348437e-02  2.50685737e-02  4.74020056e-02\n",
      "  2.18657311e-03 -1.69988181e-02  3.62671465e-02  3.46246897e-03\n",
      "  4.21937928e-03  8.04172084e-02  3.10627539e-02 -1.04941241e-03\n",
      " -3.55466679e-02  4.34836894e-02 -3.06218769e-02 -3.03192046e-02\n",
      " -4.13175039e-02 -1.05257845e-02 -2.35242657e-02 -1.86771750e-02\n",
      "  4.42935713e-03  5.45056500e-02 -6.05017617e-02  2.48421356e-02\n",
      " -3.36966515e-02 -4.54169512e-02 -2.63173133e-02  6.98055886e-03\n",
      "  6.92871660e-02 -2.04491019e-02 -1.96813252e-02 -9.72563494e-03\n",
      " -1.21564567e-02  7.89344311e-03  1.84746028e-03 -6.93651140e-02\n",
      "  2.43357178e-02  4.00609300e-02  3.44013199e-02 -2.84282118e-02\n",
      " -1.09431203e-02  1.38742616e-02 -4.40586731e-03  1.19345065e-03\n",
      " -8.81164819e-02  1.15930792e-02 -2.56351363e-02  5.57525754e-02\n",
      "  1.26946166e-01  5.39565757e-02 -1.41436690e-02  1.27196088e-02\n",
      " -1.32236090e-02 -5.94484173e-02  2.86704693e-02  2.57284623e-02\n",
      " -8.33774731e-03  8.17411405e-04  5.93052153e-03  3.29110064e-02\n",
      "  4.12751921e-02 -5.77959465e-03 -1.71124265e-02  1.06227417e-02\n",
      " -2.19601225e-02 -4.97207008e-02  2.53765658e-02 -5.60257469e-33\n",
      " -1.35397287e-02 -3.77958864e-02 -2.67925113e-03 -3.69684451e-04\n",
      " -1.98267773e-02  5.47051197e-03  6.02682307e-03  1.93068814e-02\n",
      "  3.87984910e-03  2.97698602e-02 -1.88228991e-02  2.20035738e-03\n",
      "  8.17020610e-03  1.61965620e-02  3.17528807e-02 -6.83419732e-03\n",
      "  2.19252221e-02  4.37736133e-04  2.96859350e-02 -2.62557268e-02\n",
      "  6.49379520e-03  3.56025323e-02  1.58609299e-03 -4.76583503e-02\n",
      " -5.26238792e-02  3.78274135e-02  3.54341790e-02 -3.10347676e-02\n",
      "  7.96406157e-03  5.48469052e-02 -3.56443003e-02  9.10133310e-03\n",
      " -9.45985690e-03 -4.63287048e-02 -1.63906459e-02  6.32453114e-02\n",
      " -1.38588436e-02 -5.95724657e-02 -1.57990977e-02  2.01887283e-02\n",
      " -1.98293496e-02 -3.49211209e-02  2.27938294e-02 -5.91621660e-02\n",
      "  4.18854319e-02  1.20745797e-03  5.19158840e-02 -1.88435763e-02\n",
      " -3.12101785e-02  2.34932844e-02 -7.41029903e-02 -2.76643405e-04\n",
      " -1.51720317e-02  6.11713827e-02  1.25065118e-01 -1.28459139e-02\n",
      " -1.12671312e-02  1.51750143e-03 -8.09153318e-02  1.12689221e-02\n",
      " -1.97574142e-02  2.74268165e-02  9.40989517e-03 -9.58754402e-03\n",
      "  2.54850853e-02  6.81658834e-02 -1.83453057e-02 -1.00963928e-01\n",
      " -9.45251063e-03 -5.27010998e-03  1.98684279e-02  9.80847403e-02\n",
      "  3.15633081e-02  5.30422777e-02  3.75122763e-02 -6.64209202e-02\n",
      " -5.92880286e-02 -1.57073792e-02  1.76609363e-02 -5.81073575e-02\n",
      "  2.23230962e-02  1.29869748e-02 -3.30260992e-02  9.96862887e-04\n",
      " -9.87088773e-03 -3.12955305e-02  2.28526141e-03 -4.91250195e-02\n",
      "  1.47693492e-02 -1.83367543e-02 -4.16305661e-02  3.76897231e-02\n",
      "  3.35410163e-02 -7.97111467e-02  4.01300155e-02  1.59071330e-02\n",
      "  5.06087346e-03  4.28808816e-02  2.29760185e-02 -4.13351022e-02\n",
      " -3.10503226e-02 -5.26405238e-02 -4.95404974e-02 -2.94256248e-02\n",
      "  5.94924241e-02 -2.59802919e-02  3.02497428e-02  8.80410522e-03\n",
      " -4.84466814e-02 -2.00851299e-02  9.82171856e-03 -7.89193884e-02\n",
      "  4.52883681e-03 -9.34896991e-03  9.23315529e-03 -3.17362286e-02\n",
      "  2.10833047e-02  6.37122151e-03  3.36347856e-02  3.83613966e-02\n",
      " -4.55527939e-02  1.08117214e-03 -9.83324368e-03  7.70190032e-03\n",
      " -2.87617594e-02 -1.74959507e-02 -4.27810149e-03  2.81287245e-02\n",
      "  4.97339182e-02 -7.45570958e-02 -1.07008684e-02 -7.66056823e-03\n",
      "  2.33968805e-07  1.52483070e-02  8.39614123e-02  3.67242657e-02\n",
      " -3.69249098e-02  3.64752151e-02  4.26422060e-02 -4.39825933e-03\n",
      "  1.78133491e-02 -2.67076846e-02 -7.13896984e-03  5.59975989e-02\n",
      "  3.13966051e-02  2.13440950e-03  3.90370525e-02 -8.78528655e-02\n",
      " -2.21660342e-02 -2.47735959e-02 -1.18190218e-02 -7.89705850e-03\n",
      " -2.08857395e-02  4.30556163e-02  1.07643530e-01  4.40619066e-02\n",
      "  1.47963064e-02  2.44862922e-02 -3.86268497e-02  1.80743486e-02\n",
      " -1.47836353e-03  7.74167404e-02 -4.19565551e-02 -3.80528830e-02\n",
      "  3.61258090e-02  1.59037265e-03  1.95323694e-02 -2.00079903e-02\n",
      "  4.22538593e-02  3.06111705e-02 -3.53700016e-03  5.93107985e-03\n",
      " -2.23223325e-02 -2.07131319e-02 -3.62914801e-03  1.74654126e-02\n",
      " -4.08758782e-02  5.91594800e-02 -5.89099526e-02 -3.96754295e-02\n",
      " -3.33528779e-02  1.02162119e-02  6.97288429e-03  7.70390034e-02\n",
      " -1.86911840e-02 -1.82568245e-02 -2.42318995e-02 -3.40702315e-03\n",
      " -3.60555165e-02  4.33389433e-02 -3.48603018e-02  5.27768321e-02\n",
      "  2.89710145e-02 -4.98462953e-02 -1.94748938e-02  1.16398269e-02\n",
      " -3.04614808e-02  8.04637894e-02  6.56248108e-02 -2.84533128e-02\n",
      "  1.81615255e-34 -4.19155043e-03 -2.57882345e-02  5.17320186e-02\n",
      "  4.94420901e-02  1.32476306e-02 -4.21993881e-02 -1.12458561e-02\n",
      " -2.61520278e-02  5.51130660e-02  2.20024996e-02 -2.51170527e-02]\n",
      "\n",
      "Sentence: Learn to use embeddings well and you'll be well on your way to being an AI engineer.\n",
      "Embedding: [-2.20730845e-02  2.08950639e-02 -6.03005812e-02  8.43948871e-03\n",
      "  4.37650792e-02  1.55070713e-02  4.99907359e-02 -3.03232241e-02\n",
      "  4.94784229e-02  2.35511567e-02  3.29350345e-02  1.53877279e-02\n",
      " -6.68355301e-02  1.11002885e-01  6.92676380e-02 -2.31889095e-02\n",
      "  3.79103385e-02 -4.94146161e-03 -1.57800727e-02 -3.45476307e-02\n",
      " -2.65052859e-02 -2.47879382e-02 -1.86141282e-02  3.00361793e-02\n",
      " -2.81186681e-02 -8.75139423e-03 -3.30769597e-03 -2.06116494e-02\n",
      "  1.03315711e-02 -1.51483370e-02 -3.48331258e-02 -2.63248160e-02\n",
      "  2.06907559e-02  3.79109643e-02  1.81912924e-06 -2.44292268e-03\n",
      " -1.80564087e-03  5.61760552e-03 -2.79870015e-02  1.54703036e-02\n",
      "  3.06457207e-02  3.72601785e-02 -1.55611373e-02  2.54414361e-02\n",
      " -6.42072260e-02  3.16353180e-02  6.63442686e-02  3.80970612e-02\n",
      "  5.57844974e-02  5.31660467e-02 -9.69295297e-03 -3.61424387e-02\n",
      "  3.72435041e-02 -4.67827916e-03  5.14576100e-02  1.00057805e-02\n",
      "  4.90290532e-03  1.41562745e-02  4.95099910e-02  3.32948752e-03\n",
      " -3.21100615e-02  4.42387499e-02  3.27415764e-02 -7.90620968e-03\n",
      "  1.07809767e-01  7.32944533e-02  3.36702652e-02 -4.28346172e-02\n",
      "  1.05966339e-02  2.05654055e-02 -2.02670470e-02  1.04964515e-02\n",
      " -1.97615512e-02 -2.89307009e-05 -2.61862241e-02 -1.85174029e-02\n",
      " -3.44269276e-02 -4.08620946e-02  2.32571661e-02  2.14196015e-02\n",
      "  1.31321317e-02 -3.27211283e-02 -1.91425811e-02 -2.86571998e-02\n",
      " -1.16859134e-02  1.21910451e-02  1.05248680e-02 -3.39584872e-02\n",
      "  3.08910082e-03 -4.44888882e-02  2.65104845e-02  1.09536694e-02\n",
      "  2.51450706e-02 -6.48833206e-03  4.54361038e-03 -2.02784799e-02\n",
      " -1.03216022e-02  2.06590034e-02 -1.65313538e-02 -2.45612059e-02\n",
      "  5.47549762e-02  2.68261600e-02  2.95509957e-02  3.86755131e-02\n",
      " -7.76720643e-02  3.80055532e-02 -2.98364237e-02  7.96886161e-02\n",
      " -3.00942753e-02  7.57842185e-03 -6.89827055e-02 -2.92667113e-02\n",
      " -2.35580336e-02  3.48198861e-02  2.52938662e-02 -4.53817360e-02\n",
      " -1.57939065e-02  4.39031087e-02 -4.04335894e-02  8.32528342e-03\n",
      " -2.84664743e-02  4.94933464e-02  2.41277311e-02  3.02192438e-02\n",
      " -4.99590188e-02 -5.94532825e-02 -3.70176025e-02  1.30330371e-02\n",
      " -3.36469263e-02  3.45589779e-02 -1.44523215e-02  2.57640462e-02\n",
      "  4.61187074e-03  2.21551694e-02 -4.93460894e-03  9.66004729e-02\n",
      " -2.72445753e-03  5.65333699e-04 -3.24248560e-02  1.31681589e-02\n",
      "  4.41607349e-02 -7.03056017e-03  6.84260726e-02 -2.28166897e-02\n",
      " -2.81036180e-03 -4.23883349e-02 -1.33632105e-02 -5.96738607e-02\n",
      " -6.96125533e-03 -2.31900886e-02 -3.78851295e-02  9.80186909e-02\n",
      " -2.21728850e-02 -2.30062678e-02  3.22814807e-02  8.21806025e-03\n",
      " -7.04117119e-03  4.84079495e-02  4.23291400e-02 -2.59713503e-03\n",
      "  1.20541714e-04  1.67414378e-02  2.91198045e-02 -1.28740864e-02\n",
      " -2.41077971e-02 -3.29320580e-02 -3.50295217e-03 -3.19322050e-02\n",
      " -2.64172070e-02  2.30404101e-02  1.11637088e-02 -9.95993707e-03\n",
      " -1.75901167e-02 -2.00278684e-03  1.21594900e-02  4.67823744e-02\n",
      "  5.20882308e-02  7.21172243e-02  1.94978137e-02  1.15072541e-02\n",
      "  5.94159681e-03 -1.47834169e-02 -2.87724175e-02  6.72666803e-02\n",
      " -1.68758631e-02  5.25875855e-03 -3.39739360e-02  5.24596311e-02\n",
      " -2.59793103e-02 -4.41379882e-02  1.47448096e-03 -1.06599182e-02\n",
      " -1.51859540e-02 -1.55877182e-03  1.81504674e-02 -4.85410951e-02\n",
      "  3.67904105e-03 -6.59313202e-02 -1.49418367e-02 -3.23530100e-02\n",
      " -2.79949158e-02  1.71856489e-02 -7.87079521e-03  4.65692282e-02\n",
      "  1.47123551e-02 -7.40438998e-02 -6.52104244e-02 -5.22735082e-02\n",
      " -1.82343703e-02  5.20859435e-02  3.06304395e-02 -2.36037746e-02\n",
      "  2.42384635e-02 -1.83940288e-02 -4.83012013e-03 -2.13385988e-02\n",
      "  1.56584159e-02  9.87342186e-03 -4.25561517e-02  6.00460451e-03\n",
      " -3.14499368e-03  4.51517617e-03 -1.52777124e-03  1.13731483e-02\n",
      " -6.96354136e-02 -3.37258242e-02  1.33406920e-02  4.87287948e-03\n",
      " -7.81487487e-03  4.78049256e-02 -1.59711726e-02  3.14606391e-02\n",
      "  5.15920706e-02 -4.05122116e-02 -5.06460816e-02  9.99934319e-03\n",
      " -2.00729854e-02  4.21552397e-02  3.03183198e-02 -1.00431219e-01\n",
      " -4.12020199e-02  3.43990996e-02  3.29209454e-02  1.07407628e-03\n",
      "  3.70962545e-02 -6.94237575e-02  6.52393401e-02  8.31663422e-03\n",
      "  1.68036241e-02 -2.60706171e-02  8.14504176e-03 -1.48009360e-02\n",
      " -2.65670698e-02  3.29321958e-02 -7.37516070e-03  7.23971799e-03\n",
      " -2.69330572e-02  1.71755087e-02 -2.28083264e-02 -4.75339452e-03\n",
      "  2.88568903e-02  1.30799963e-04  5.44129051e-02 -1.43378796e-02\n",
      "  1.89891979e-02 -1.32732373e-02  4.01178114e-02 -7.29275420e-02\n",
      " -2.41210684e-02  3.16217318e-02 -1.68014113e-02  8.47541634e-03\n",
      " -5.23940809e-02 -1.43883079e-02 -1.46156643e-02  6.39907178e-03\n",
      "  2.15113703e-02 -5.18960543e-02 -4.30576354e-02  2.34075673e-02\n",
      "  2.30274559e-03 -2.48434320e-02 -4.38243560e-02 -2.16570254e-02\n",
      " -6.91595450e-02  1.76770203e-02  2.12066881e-02 -2.20294632e-02\n",
      " -1.06772473e-02  9.57422052e-03  2.21989099e-02  5.51471077e-02\n",
      "  1.03683220e-02 -8.14824477e-02 -7.94707891e-03 -1.85866877e-02\n",
      "  1.20494254e-02  7.51402974e-02 -1.41215837e-02  8.83924738e-02\n",
      "  3.12628485e-02  8.12260062e-03 -2.29444169e-02  3.96010876e-02\n",
      " -2.00168155e-02  9.16027352e-02 -2.06839293e-02  5.84991127e-02\n",
      " -4.32368778e-02 -4.74743592e-03 -9.51887295e-03  5.42947417e-03\n",
      "  1.19156386e-04  6.15376271e-02 -1.68786745e-03 -4.66320775e-02\n",
      " -2.01405510e-02  1.32406000e-02  9.70685203e-03  2.73847859e-02\n",
      "  3.06639690e-02  6.71581551e-03  8.71220976e-02 -1.97369978e-03\n",
      "  8.18297639e-03  5.44354413e-03 -5.76205924e-02  1.34820752e-02\n",
      "  5.06296242e-03 -2.10569091e-02  1.25937201e-02 -5.49785513e-03\n",
      " -1.44645618e-02 -2.92567126e-02  5.53298555e-02 -2.60099042e-02\n",
      " -2.82455655e-03 -2.30901558e-02  8.89707729e-03 -2.61565391e-02\n",
      "  9.08635498e-04 -6.16203807e-02 -7.56419748e-02 -1.05931805e-02\n",
      " -1.19563797e-02  6.71458542e-02 -1.96234751e-02 -5.00934198e-02\n",
      " -3.91229168e-02 -3.07007935e-02  7.18906373e-02  9.29245166e-03\n",
      " -6.34386577e-03  7.86987366e-04 -1.36483898e-02  2.87189167e-02\n",
      "  4.01225053e-02  1.28036886e-02  1.77381262e-02 -4.75977641e-03\n",
      "  5.47173582e-02  1.10808539e-03 -2.25790478e-02 -2.80288258e-03\n",
      " -1.13696031e-01  2.55904701e-02  4.00443590e-04 -4.39811796e-02\n",
      "  1.36319371e-02 -1.54137434e-02 -4.99015264e-02 -2.32889634e-02\n",
      " -1.62989122e-03  3.95835638e-02  1.89040676e-02 -3.02703511e-02\n",
      "  2.71438174e-02  1.05674518e-03 -4.21069898e-02  3.71961147e-02\n",
      "  3.54258455e-02 -6.98274672e-02 -2.20937692e-02 -4.01496440e-02\n",
      " -1.90164410e-02 -2.69835368e-02 -1.51213342e-02  3.33365612e-02\n",
      " -9.74889621e-02  1.73102394e-02  6.21018326e-03 -2.59428914e-03\n",
      " -1.10152982e-01 -6.10186532e-02 -1.36549585e-02 -1.35035273e-02\n",
      " -6.72573224e-02 -4.05125227e-03 -6.64986251e-03  3.86565807e-03\n",
      "  9.43469349e-03 -3.86636779e-02 -1.93592682e-02  1.34934187e-02\n",
      " -4.58106846e-02  6.06737062e-02  6.06380291e-02  4.85597067e-02\n",
      " -4.56088446e-02 -5.71936667e-02 -1.55094741e-02  3.40963155e-02\n",
      "  9.48150700e-04 -9.94347595e-03  2.84657534e-02 -3.29024158e-02\n",
      " -2.83210967e-02  3.19907703e-02  2.61298828e-02 -2.74054799e-02\n",
      " -1.36353448e-02  7.47712236e-03  1.19430326e-01 -4.45806906e-02\n",
      "  1.07670920e-02 -8.69424120e-02 -2.19550952e-02  1.83874704e-02\n",
      " -1.06521370e-02 -1.89242959e-02 -3.06513794e-02 -3.04701943e-02\n",
      " -3.22214440e-02  4.12151329e-02  8.95753223e-03 -2.73180157e-02\n",
      "  9.39995516e-03 -9.57126729e-04 -1.94009971e-02 -4.92623262e-02\n",
      " -9.18887835e-03  4.66894433e-02  5.41892760e-02  2.21609268e-02\n",
      " -2.86351703e-02  5.20295613e-02  2.47588996e-02 -7.14268759e-02\n",
      " -1.26206372e-02  7.35518523e-03  2.13784464e-02  2.93514356e-02\n",
      " -2.57651377e-02  5.20562753e-02 -2.74891946e-02 -3.10242716e-02\n",
      " -9.02879611e-02  6.10371530e-02 -5.22609726e-02  2.13111471e-02\n",
      "  4.41734791e-02  3.23371030e-02  1.75648239e-02 -2.39520259e-02\n",
      " -2.69709621e-02  5.11278249e-02  2.69065760e-02 -4.51932512e-02\n",
      "  2.52655265e-03  2.44934019e-02 -2.89541353e-02  2.79992912e-02\n",
      " -1.36022465e-02 -4.32368964e-02  1.85830668e-02  7.63895878e-05\n",
      "  2.43517384e-03 -3.73321120e-03 -1.72279831e-02  1.01292692e-02\n",
      "  1.98437572e-02 -2.60018241e-02 -3.40175955e-03  1.09125422e-02\n",
      " -4.16363627e-02  3.37031856e-02 -2.81635225e-02  1.79126374e-02\n",
      " -4.53095101e-02 -1.09819816e-02 -2.20821542e-03  1.99103057e-02\n",
      "  3.56371924e-02 -3.11799180e-02  3.78751867e-02 -1.41409356e-02\n",
      " -2.16907077e-02  2.73019504e-02  3.69819347e-03  6.35388270e-02\n",
      "  1.22669153e-02 -6.02275087e-03 -7.60759925e-03 -1.86565313e-02\n",
      " -5.64719597e-03 -2.20050500e-03 -1.31825153e-02  1.67724397e-02\n",
      " -3.77264954e-02  2.97894981e-02 -5.01569882e-02  4.89088036e-02\n",
      " -6.07444309e-02 -8.39418843e-02 -5.09001613e-02  1.81767885e-02\n",
      "  6.66732714e-02 -3.30041186e-03 -2.82399263e-03 -5.35406917e-02\n",
      "  3.90341431e-02  2.19852906e-02  3.13555673e-02 -3.36527340e-02\n",
      "  1.96913276e-02  1.67883635e-02  5.04003018e-02  3.08056991e-03\n",
      " -7.24759535e-04  4.42907177e-02 -4.12961049e-03  4.29328978e-02\n",
      " -6.62552118e-02  1.16052735e-03 -2.81716641e-02  1.56886373e-02\n",
      "  9.78133455e-02  5.53594790e-02 -1.39379166e-02  2.12307479e-02\n",
      " -1.30956182e-02 -6.82027936e-02 -8.09031655e-04  4.99291979e-02\n",
      " -2.69265622e-02 -2.97803748e-02  3.84462103e-02  1.97354015e-02\n",
      "  3.37088369e-02  1.65873673e-02  5.77314524e-03 -3.04897372e-02\n",
      " -1.52511885e-02 -3.56159434e-02 -8.69222078e-03 -5.42296943e-33\n",
      "  3.24369734e-03 -3.46329771e-02  3.58933099e-02  1.83771178e-02\n",
      " -2.17504799e-02 -3.26412097e-02  2.88397982e-03  1.50463758e-02\n",
      " -1.75258634e-03 -1.99418887e-02 -6.10350026e-03  2.23847162e-02\n",
      " -8.78936611e-04  2.48685181e-02  3.39736007e-02  2.75592823e-02\n",
      "  3.37792337e-02  3.98565158e-02  2.55545862e-02  1.83042474e-02\n",
      " -2.92878542e-02  5.18083805e-03  8.37831467e-04 -3.66560668e-02\n",
      " -3.46733443e-02  3.82687338e-02  5.50821517e-03 -4.35187779e-02\n",
      "  2.44077463e-02  3.54167782e-02 -2.13442538e-02  2.86623873e-02\n",
      " -2.65416835e-04  3.73409800e-02 -8.68166983e-03  3.04785278e-03\n",
      " -2.71682274e-02 -3.85088213e-02 -6.12388141e-02 -2.00842042e-03\n",
      " -1.22080427e-02 -8.67198259e-02  3.75359296e-03 -1.77707225e-02\n",
      "  8.32483452e-03 -1.69167295e-02  7.02404082e-02  3.32233943e-02\n",
      "  4.34313044e-02  1.47017129e-02 -1.25546947e-01  1.50866592e-02\n",
      " -5.43164425e-02 -1.79149443e-03  4.99601029e-02 -1.53786168e-02\n",
      "  3.32683101e-02 -3.07708886e-02 -1.83896609e-02  9.45800357e-03\n",
      " -4.60291319e-02 -2.03870703e-03  2.62428466e-02 -5.00788800e-02\n",
      "  2.01836023e-02  6.08983077e-02 -2.01180708e-02 -2.60054041e-02\n",
      "  1.05925249e-02 -3.31153423e-02  1.62595548e-02  7.77862594e-02\n",
      " -1.90731359e-03 -5.62886242e-03  1.43716335e-02 -4.06833403e-02\n",
      " -5.14971018e-02  1.66211568e-04 -3.33050708e-03  1.44688822e-02\n",
      "  4.24896774e-04  3.04453466e-02 -1.83636416e-02  1.51193223e-03\n",
      "  2.99861450e-02 -3.68002243e-02  8.35622288e-03 -3.31025496e-02\n",
      "  2.66911518e-02  5.47830947e-03 -1.80524010e-02  2.42578015e-02\n",
      "  5.72706759e-03 -5.93372211e-02  1.04358405e-01 -9.87923238e-03\n",
      " -1.36106024e-02  5.79999052e-02  2.50108410e-02  2.89337132e-02\n",
      " -3.20520774e-02 -3.40233222e-02 -3.41698490e-02 -2.76982263e-02\n",
      "  6.47003129e-02  1.50797954e-02 -1.61924995e-02  3.03266440e-02\n",
      " -2.67188158e-02 -3.67774479e-02 -2.27845442e-02 -5.36433868e-02\n",
      "  1.90499946e-02 -3.42503153e-02  1.32688154e-02 -5.41318068e-03\n",
      "  7.49740703e-03 -7.36949733e-04 -3.08569316e-02  3.82288806e-02\n",
      " -2.08311435e-02 -3.43154818e-02  5.60238352e-03  1.44998990e-02\n",
      " -3.76364179e-02 -5.11782952e-02 -3.51075344e-02  1.71867553e-02\n",
      "  1.50721464e-02 -9.62026864e-02 -1.53544899e-02  1.58376116e-02\n",
      "  2.42940985e-07 -5.88800386e-03  7.68796504e-02  5.86063266e-02\n",
      "  2.21232716e-02 -2.36690827e-02  5.25273867e-02  1.48661714e-02\n",
      "  7.34176021e-03 -4.98924078e-03  4.37413938e-02 -1.28331967e-02\n",
      "  3.37342322e-02 -1.10814925e-02 -1.33937784e-02 -7.80064315e-02\n",
      " -1.36330836e-02  1.94749255e-02  1.91745989e-03 -3.00251767e-02\n",
      "  1.02725644e-04  9.54532474e-02  1.19654059e-01  3.73372398e-02\n",
      "  4.25129058e-03  2.05130260e-02 -3.85414921e-02 -1.90614462e-02\n",
      "  5.88793010e-02  6.81264475e-02 -3.12595628e-02 -6.50440454e-02\n",
      "  2.48043984e-02  3.90113011e-04  7.54762292e-02 -3.46075669e-02\n",
      "  1.32949697e-02  4.14005667e-02  3.07568815e-02  5.50350733e-03\n",
      " -1.53088721e-03  2.75993478e-02  6.46030298e-03  1.05398363e-02\n",
      " -3.09298523e-02  4.60232459e-02 -3.64920348e-02 -1.39539978e-02\n",
      " -3.53721306e-02  7.97826855e-04  1.40632959e-02  1.80258453e-02\n",
      " -1.43368784e-02  2.19214172e-03 -3.96873318e-02 -1.17282048e-02\n",
      " -4.45219986e-02  8.05771910e-03 -4.04862277e-02  3.56148668e-02\n",
      "  5.12852967e-02 -6.64038658e-02 -5.32595105e-02  8.92900024e-03\n",
      "  1.56424027e-02  1.02110989e-01  8.10764357e-03 -4.03858488e-03\n",
      "  2.02352651e-34 -1.38293831e-02 -1.17623648e-02  1.51005667e-02\n",
      "  8.25896040e-02  2.39228588e-02 -1.10378107e-02  3.65659525e-03\n",
      " -7.44782994e-03  2.94555221e-02  3.52998707e-03 -6.10421635e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Requires !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=\"cpu\") # choose the device to load the model to (note: GPU will often be *much* faster than CPU)\n",
    "\n",
    "# Create a list of sentences to turn into numbers\n",
    "sentences = [\n",
    "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
    "    \"Sentences can be embedded one by one or as a list of strings.\",\n",
    "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
    "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
    "]\n",
    "\n",
    "# Sentences are encoded/embedded by calling model.encode()\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "# See the embeddings\n",
    "for sentence, embedding in embeddings_dict.items():\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! That's a lot of numbers.\n",
    "\n",
    "How about we do just once sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Yo! How cool are embeddings?\n",
      "Embedding:\n",
      "[-1.97448079e-02 -4.51076636e-03 -4.98487381e-03  6.55445009e-02\n",
      " -9.87673923e-03  2.72835921e-02  3.66426446e-02 -3.30219488e-03\n",
      "  8.50078370e-03  8.24952591e-03 -2.28497572e-02  4.02430035e-02\n",
      " -5.75200468e-02  6.33692071e-02  4.43207324e-02 -4.49506305e-02\n",
      "  1.25284633e-02 -2.52011809e-02 -3.55292968e-02  1.29559245e-02\n",
      "  8.67021270e-03 -1.92917809e-02  3.55636817e-03  1.89505816e-02\n",
      " -1.47128142e-02 -9.39845107e-03  7.64174573e-03  9.62185301e-03\n",
      " -5.98922325e-03 -3.90168838e-02 -5.47824688e-02 -5.67454379e-03\n",
      "  1.11644613e-02  4.08067293e-02  1.76319122e-06  9.15304385e-03\n",
      " -8.77259858e-03  2.39382703e-02 -2.32784487e-02  8.05000216e-02\n",
      "  3.19177061e-02  5.12601668e-03 -1.47708217e-02 -1.62524972e-02\n",
      " -6.03212900e-02 -4.35689948e-02  4.51211371e-02 -1.79053862e-02\n",
      "  2.63366625e-02 -3.47866677e-02 -8.89173150e-03 -5.47675341e-02\n",
      " -1.24373063e-02 -2.38606650e-02  8.33497196e-02  5.71241640e-02\n",
      "  1.13328611e-02 -1.49594918e-02  9.20378566e-02  2.72709802e-02\n",
      " -1.42185530e-02  1.91209018e-02  1.49963051e-02 -3.12198531e-02\n",
      "  8.99579152e-02  4.51188534e-02  2.58020908e-02 -5.51738171e-03\n",
      "  1.15909884e-02  4.72100526e-02 -1.51018854e-02  1.70818083e-02\n",
      " -7.22598005e-03  3.45763564e-02 -8.76467116e-03  5.22016734e-02\n",
      " -6.49008751e-02 -4.31378447e-02  6.36964813e-02  4.02881205e-02\n",
      " -1.99042615e-02  5.39058261e-03  1.28820799e-02 -4.81255278e-02\n",
      "  4.58800457e-02 -2.17094328e-02  1.89203527e-02 -3.46344598e-02\n",
      " -1.66457109e-02  7.65165407e-03 -2.26693526e-02 -1.96454152e-02\n",
      "  1.87632125e-02  1.01382919e-02  6.85413182e-02 -5.39850537e-03\n",
      " -3.38229351e-03  4.08413000e-02  4.98624220e-02 -1.16485925e-02\n",
      "  8.91738683e-02  4.02786061e-02 -3.64716258e-03  4.37758863e-02\n",
      " -2.96080150e-02 -5.53755136e-03 -2.00209171e-02 -2.01982632e-02\n",
      "  4.59848829e-02  2.29337625e-02 -5.37306257e-02 -3.19279321e-02\n",
      "  1.37541001e-03  6.25036508e-02 -2.18308363e-02 -6.43256158e-02\n",
      " -2.24791840e-02  3.31955180e-02 -3.12837735e-02  5.17935865e-02\n",
      " -2.84003429e-02  2.55067609e-02  3.36493403e-02  7.50668421e-02\n",
      " -4.46475344e-03 -4.87705767e-02 -7.35218823e-02 -5.46352714e-02\n",
      "  8.88529047e-03  2.95797791e-02 -9.95697454e-03 -6.32764213e-03\n",
      "  4.46259417e-02 -1.58483703e-02 -1.71330310e-02  3.36602740e-02\n",
      " -1.57664437e-03 -5.45971617e-02  2.91160736e-02 -2.80596316e-02\n",
      "  2.96793692e-02  5.12153432e-02  1.48765557e-02 -4.76488359e-02\n",
      "  1.26052229e-02  1.49851129e-03  1.33206239e-02 -2.82469429e-02\n",
      " -3.29254717e-02 -8.53571296e-03 -5.27608208e-02  7.29350448e-02\n",
      " -6.41821325e-02 -2.51785060e-03 -9.02636722e-03 -1.10466010e-03\n",
      "  1.57513972e-02  4.30823527e-02  1.12269167e-02 -3.54586132e-02\n",
      "  4.95163351e-02  1.21271126e-02  1.66344317e-03 -5.06922835e-03\n",
      " -1.11001739e-02 -8.66921805e-03 -3.26440223e-02 -3.98021713e-02\n",
      " -2.05970686e-02  1.09074200e-02 -6.62528872e-02  3.71706635e-02\n",
      " -3.74916941e-02 -3.24730948e-02  5.85900396e-02  8.48081186e-02\n",
      "  3.92412841e-02  3.15815508e-02  3.78385894e-02 -1.35472491e-02\n",
      "  5.95062412e-02  2.58905180e-02 -1.31899947e-02  6.30589724e-02\n",
      "  3.27135846e-02  6.92145852e-03 -1.42607307e-02  7.76676163e-02\n",
      " -1.16102872e-02 -3.66427936e-02 -2.83837952e-02  2.72279978e-02\n",
      "  2.49364600e-02 -4.22296021e-03 -3.63101140e-02 -2.04887521e-02\n",
      "  3.98861468e-02 -2.64726095e-02  4.41383477e-03 -5.19635752e-02\n",
      "  1.71393094e-05  4.81284484e-02  2.04450693e-02  9.84969810e-02\n",
      "  3.68267670e-02  1.53404567e-02  7.50950538e-04 -3.38638648e-02\n",
      " -2.69872881e-02  4.72444519e-02  4.56701927e-02 -3.49246562e-02\n",
      " -1.18770804e-02  3.45576508e-03 -6.32301066e-03 -4.78412360e-02\n",
      "  1.84098352e-02 -2.23157424e-02 -3.70728113e-02  5.87339513e-02\n",
      "  6.22728793e-03 -1.46716274e-02  7.29223192e-02  2.21959059e-03\n",
      " -6.53119832e-02  3.51679251e-02 -1.54901603e-02  6.01421110e-02\n",
      " -9.41004697e-03  2.81196795e-02 -1.12651773e-02  5.24135830e-04\n",
      "  1.01888627e-01 -5.69957457e-02 -3.52360755e-02 -5.20479586e-03\n",
      " -8.46641883e-03  1.39209395e-02  1.80780347e-02 -1.10493906e-01\n",
      "  5.13116717e-02 -4.36431766e-02  2.84142885e-02  9.55938641e-03\n",
      "  4.28096615e-02 -3.95833366e-02  5.25829345e-02  1.92814544e-02\n",
      "  3.44890356e-03 -1.76871661e-02  3.85699868e-02  6.92506554e-03\n",
      " -3.59440185e-02 -2.63612978e-02 -4.96695284e-03  4.24525551e-02\n",
      " -4.22464274e-02  3.45900841e-03  3.55866700e-02 -1.68202203e-02\n",
      "  3.54331955e-02  4.52804007e-03  6.46289485e-03 -2.17710752e-02\n",
      " -2.50033159e-02  1.41418679e-02  1.51257757e-02 -2.99570095e-02\n",
      " -3.94227207e-02  1.87821910e-02 -1.68780040e-03 -9.83481063e-04\n",
      " -3.26321684e-02  5.06562367e-03 -8.90459027e-03 -1.55095169e-02\n",
      "  1.87758189e-02 -4.52473611e-02 -1.72957182e-02  3.50973271e-02\n",
      "  1.33018577e-02  1.00632841e-02 -4.36593182e-02 -1.68619119e-02\n",
      " -1.91048328e-02  6.35489821e-02  8.08323454e-03 -1.02532795e-02\n",
      " -4.53627668e-03 -4.60835509e-02 -1.64704341e-02 -6.24680799e-03\n",
      "  2.58868504e-02 -6.39063939e-02 -7.82403629e-03 -2.36076526e-02\n",
      "  2.74617765e-02  5.80534711e-02 -3.40748802e-02  6.46012202e-02\n",
      "  2.00062692e-02 -2.14934964e-02  1.69360917e-02 -5.54069551e-03\n",
      " -2.40397695e-02  3.09444014e-02 -2.34439643e-03  3.02589163e-02\n",
      " -4.57217880e-02  2.00641248e-02 -2.57117022e-02 -1.13375823e-03\n",
      " -3.57524566e-02  6.92953393e-02  2.80850590e-03  3.58741991e-02\n",
      " -1.52722383e-02 -3.41523662e-02  1.80923417e-02  1.65399723e-02\n",
      "  1.31705785e-02 -6.36673020e-03  5.49302995e-02  8.47313646e-03\n",
      " -4.26077023e-02  2.17084587e-02 -4.89023253e-02  1.18863267e-04\n",
      "  5.16287386e-02  7.59189541e-04  1.59222912e-02 -1.61299556e-02\n",
      "  1.44981500e-02  2.19509378e-02  3.02651729e-02 -3.44151407e-02\n",
      " -4.80380133e-02 -3.71690318e-02  4.68194708e-02 -3.46219130e-02\n",
      "  4.74860281e-04 -4.34820689e-02 -1.80124901e-02 -6.44844621e-02\n",
      " -2.66967174e-02  3.63660827e-02 -3.76219861e-02 -1.64600406e-02\n",
      "  2.20248625e-02  2.16066779e-04  3.64510976e-02 -2.76135784e-02\n",
      " -5.87058300e-03  6.97315391e-03 -1.25862833e-03  2.12774072e-02\n",
      "  6.21470343e-03 -3.57215181e-02 -5.09366356e-02  2.85552889e-02\n",
      "  6.48822635e-02  3.45731638e-02 -2.57280990e-02  4.52562748e-03\n",
      " -4.63605933e-02  3.32225636e-02  1.69973925e-03 -1.29355360e-02\n",
      " -3.03734597e-02  1.23609342e-02 -3.17980710e-04  1.66231431e-02\n",
      "  1.04892347e-02  1.71540696e-02  1.88860297e-02 -3.62256654e-02\n",
      "  4.65737469e-02  2.17128322e-02  4.97535728e-02  3.03067770e-02\n",
      "  1.59914303e-03 -6.30024597e-02 -6.34593004e-03  1.07329710e-04\n",
      " -5.56749385e-03  2.37264726e-02 -8.38229153e-03  5.38897701e-02\n",
      " -9.08976942e-02 -1.37359845e-02  1.18454508e-02  3.37255397e-03\n",
      " -2.81855855e-02  1.56339363e-03  2.22415663e-02  6.21023923e-02\n",
      " -8.68120044e-02 -4.40636650e-03 -1.63995381e-02  1.69665273e-02\n",
      " -1.34548284e-02  3.00698541e-03 -2.14618444e-02 -2.09503956e-02\n",
      " -1.39877805e-02 -1.23850219e-02  5.39979003e-02  6.03614114e-02\n",
      "  2.52982546e-02 -1.29661441e-01 -1.08081430e-01 -4.15774761e-03\n",
      " -7.20272120e-03  2.75885053e-02  4.87621874e-02 -2.95970812e-02\n",
      " -4.32554930e-02  2.75215730e-02  1.35718519e-02  3.87699790e-02\n",
      "  2.42039785e-02 -2.70842258e-02  8.59166682e-02 -1.98402815e-02\n",
      " -2.26344001e-02 -6.24927692e-02 -1.56845264e-02  4.11567055e-02\n",
      "  1.66952405e-02  7.97291845e-02 -3.24839093e-02  1.46563316e-03\n",
      " -3.27906273e-02  6.44815192e-02  2.09739450e-02 -7.56986216e-02\n",
      " -1.31790130e-03  2.24049482e-03 -6.60841493e-03 -6.84251860e-02\n",
      " -5.36860619e-03  6.55135959e-02  5.45556238e-03  1.58993993e-02\n",
      " -2.18052194e-02  2.16425559e-03  4.72951960e-03 -7.25655630e-02\n",
      " -1.59349907e-02 -1.05623333e-02  2.70786677e-02  1.93769729e-03\n",
      " -4.45122980e-02  2.89783310e-02  2.43084468e-02 -1.73885673e-02\n",
      " -3.80669758e-02 -3.06798890e-02 -3.24778371e-02 -4.33351583e-04\n",
      "  2.55846158e-02  2.70478465e-02 -1.72466462e-04 -4.93684260e-04\n",
      " -7.12094754e-02  5.69768846e-02  6.61400929e-02 -3.87268029e-02\n",
      " -1.30683435e-02  1.00663640e-02 -2.17740573e-02  1.92212462e-02\n",
      "  7.66689843e-03 -3.86652686e-02 -1.66108515e-02 -3.41467932e-02\n",
      " -1.04185585e-02  1.75905805e-02 -1.23775918e-02 -1.68433748e-02\n",
      " -2.40113158e-02  4.70198831e-03  4.88464022e-03  4.73663509e-02\n",
      "  4.34112065e-02 -8.08341056e-03 -2.48272456e-02 -1.93978194e-02\n",
      " -3.16524878e-02 -1.56419128e-02 -7.79946335e-03  1.28888786e-02\n",
      "  2.61943750e-02  3.65821668e-03  5.79228662e-02  5.43151386e-02\n",
      " -5.05586453e-02  1.78925204e-03 -2.45471094e-02 -2.47595944e-02\n",
      "  3.60357598e-03  1.94152258e-02 -4.23823223e-02 -1.86907481e-02\n",
      "  2.32945606e-02 -3.17982584e-02 -2.60645803e-02 -5.40361460e-03\n",
      " -3.82070169e-02  2.21719872e-02  1.33360652e-02  5.58054037e-02\n",
      " -3.57716791e-02 -3.54791582e-02  1.27723478e-02  6.80177361e-02\n",
      "  5.37152290e-02  2.54151784e-02 -1.16638709e-02 -1.07512921e-02\n",
      " -9.74431541e-03  7.20505463e-03  9.21898987e-03 -4.73685004e-02\n",
      " -3.89393792e-03  3.11453473e-02  3.62332053e-02 -1.65902879e-02\n",
      " -3.63394730e-02  1.95634495e-02 -2.15058755e-02 -7.04767089e-03\n",
      "  9.13173053e-03 -4.05358672e-02 -3.67076285e-02  1.16995893e-01\n",
      "  1.17913894e-01  8.00503194e-02 -1.61983501e-02 -2.00733412e-02\n",
      " -5.54062016e-02 -7.22410604e-02  2.14557741e-02 -4.46385355e-04\n",
      " -1.42902723e-02  8.35543405e-03  3.34207453e-02  1.42891090e-02\n",
      "  4.62512374e-02 -3.53420191e-02  1.68673452e-02 -2.99736368e-03\n",
      " -5.44997118e-02 -4.80719283e-02  9.47574328e-04 -6.29721507e-33\n",
      " -2.30286550e-02 -2.51128282e-02 -5.35218827e-02 -2.09469683e-02\n",
      " -6.79710461e-03 -4.64015529e-02 -4.49634902e-03  1.65114608e-02\n",
      " -1.12677291e-02  1.33013632e-02 -1.72552876e-02 -1.96653754e-02\n",
      "  5.53236343e-03  1.02775376e-02  9.47371649e-04 -2.24022195e-02\n",
      "  5.30364737e-02  7.77776539e-03 -9.48472973e-03  2.25515813e-02\n",
      " -4.34491923e-03  2.25208774e-02  1.98086426e-02 -7.57428035e-02\n",
      " -4.36685281e-03  2.50829384e-02  2.59393565e-02 -3.07077151e-02\n",
      "  7.04764277e-02  8.63500759e-02 -7.75880516e-02  1.59991365e-02\n",
      " -5.04692644e-02  4.88354862e-02  3.74993077e-03 -6.12939533e-04\n",
      " -3.87277827e-02 -2.32235231e-02 -3.63983437e-02 -5.07018063e-03\n",
      "  1.10517722e-02 -3.26515324e-02  3.68386805e-02 -4.54948805e-02\n",
      " -1.18527818e-03  1.92688208e-03  2.18783375e-02  2.71092877e-02\n",
      " -4.06264253e-02  6.99159876e-02 -7.33281896e-02 -8.15296173e-03\n",
      " -1.42555758e-02  3.78036895e-03  1.20974340e-01 -6.68212548e-02\n",
      "  3.05051189e-02  1.24480240e-02 -4.59293872e-02  1.03873126e-02\n",
      " -3.97978313e-02 -1.33041944e-02 -1.59402154e-02 -4.29347381e-02\n",
      "  4.05275710e-02  7.07073808e-02 -4.50929180e-02 -3.62474285e-02\n",
      " -1.87589116e-02  1.60928331e-02  2.12657377e-02  6.70025051e-02\n",
      "  3.25864293e-02  1.51125668e-02  3.20371576e-02 -1.35436337e-02\n",
      "  2.31780056e-02 -1.13125695e-02  1.23795923e-02 -3.73516977e-02\n",
      "  1.55545736e-03  2.15824861e-02 -3.49442661e-02 -2.97690630e-02\n",
      "  2.32397355e-02 -1.25703309e-02 -1.09433159e-02 -8.87968764e-02\n",
      " -2.20183544e-02 -1.18423179e-02 -5.71083948e-02  3.91810201e-02\n",
      " -1.98827125e-02 -5.59270270e-02  7.60342926e-03  2.23641805e-02\n",
      " -1.86267123e-02  3.79805304e-02 -8.79658503e-04 -5.26199751e-02\n",
      "  2.05064914e-03  1.72814652e-02 -4.84028570e-02 -1.87740549e-02\n",
      "  1.72628532e-07  2.06594728e-02  3.03574987e-02  5.71856089e-03\n",
      " -5.33938445e-02 -2.46520769e-02  1.80340838e-02 -3.39978226e-02\n",
      "  3.46288107e-05 -6.40036166e-02  2.50049625e-02 -2.04111710e-02\n",
      " -2.72035250e-03 -3.55961844e-02  2.71922965e-02  6.48939908e-02\n",
      "  9.83429141e-04 -4.38490845e-02 -4.45297472e-02 -7.44889444e-03\n",
      "  1.15205543e-02 -2.91255512e-03 -2.15495583e-02  2.84253457e-03\n",
      "  4.29398939e-02 -6.09041266e-02 -7.86321983e-03 -3.90128372e-03\n",
      "  2.47718305e-07  7.75868073e-04  7.47736916e-02  1.99318258e-03\n",
      " -6.07218686e-03  3.69210467e-02  2.78421268e-02 -5.64900450e-02\n",
      "  1.61059052e-02 -9.50824656e-03 -2.60850717e-03 -2.45737005e-02\n",
      "  1.91390570e-02  5.08195497e-02  2.61258949e-02 -1.03838123e-01\n",
      " -3.05815227e-02 -3.53344940e-02 -4.07037511e-02 -2.19842959e-02\n",
      " -2.24092416e-02  5.05567938e-02  7.22607523e-02  5.54790162e-02\n",
      "  4.89433967e-02  3.37951444e-03 -6.84760138e-02  7.10323453e-03\n",
      "  3.15671926e-03  4.78091650e-02 -7.19795227e-02 -3.30301672e-02\n",
      "  3.19159143e-02  1.76427979e-03 -4.62789796e-02 -1.96378808e-02\n",
      "  1.67493895e-02  4.73603681e-02 -2.09441446e-02  7.10246200e-03\n",
      "  4.53146286e-02 -4.76523489e-02 -4.74881679e-02  1.00799920e-02\n",
      " -8.39594007e-02  3.36930007e-02 -3.72189283e-02  1.19433161e-02\n",
      " -3.16896178e-02 -1.29724562e-03 -1.55540891e-02  1.81728061e-02\n",
      " -1.49368308e-02 -1.70671716e-02 -4.19716649e-02  3.94657115e-03\n",
      " -2.24302020e-02  2.07292251e-02 -4.61415760e-02  8.50219186e-03\n",
      " -2.56864503e-02 -1.65337734e-02 -1.51846120e-02 -1.00041600e-02\n",
      "  2.19642725e-02  2.61104815e-02  7.31358901e-02 -1.83709580e-02\n",
      "  1.93979481e-34 -7.27933319e-03  5.96487103e-03  4.44310680e-02\n",
      "  4.14822362e-02  1.12916911e-02 -1.93217974e-02  4.41879481e-02\n",
      " -8.93790089e-03  3.61119956e-02 -5.52125908e-02 -2.89572421e-02]\n",
      "Embedding size: (768,)\n"
     ]
    }
   ],
   "source": [
    "single_sentence = \"Yo! How cool are embeddings?\"\n",
    "single_embedding = embedding_model.encode(single_sentence)\n",
    "print(f\"Sentence: {single_sentence}\")\n",
    "print(f\"Embedding:\\n{single_embedding}\")\n",
    "print(f\"Embedding size: {single_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We've now got a way to numerically represent each of our chunks.\n",
    "\n",
    "Our embedding has a shape of `(768,)` meaning it's a vector of 768 numbers which represent our text in high-dimensional space, too many for a human to comprehend but machines love high-dimensional space.\n",
    "\n",
    "> **Note:** No matter the size of the text input to our `all-mpnet-base-v2` model, it will be turned into an embedding size of `(768,)`. This value is fixed. So whether a sentence is 1 token long or 1000 tokens long, it will be truncated/padded with zeros to size 384 and then turned into an embedding vector of size `(768,)`. Of course, other embedding models may have different input/output shapes.\n",
    "\n",
    "How about we add an embedding field to each of our chunk items?\n",
    "\n",
    "Let's start by trying to create embeddings on the CPU, we'll time it with the `%%time` magic to see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Uncomment to see how long it takes to create embeddings on CPU\n",
    "# # Make sure the model is on the CPU\n",
    "# embedding_model.to(\"cpu\")\n",
    "\n",
    "# # Embed each chunk one by one\n",
    "# for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "#     item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok not too bad... but this would take a *really* long time if we had a larger dataset.\n",
    "\n",
    "Now let's see how long it takes to create the embeddings with a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a8eba5224449b19af51a43450e099f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 54s\n",
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Send the model to the GPU\n",
    "embedding_model.to(\"cuda\") # requires a GPU installed, for reference on my local machine, I'm using a NVIDIA RTX 4090\n",
    "\n",
    "# Create embeddings one by one on the GPU\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! Looks like the embeddings get created much faster (~10x faster on my machine) on the GPU!\n",
    "\n",
    "You'll likely notice this trend with many of your deep learning workflows. If you have access to a GPU, especially a NVIDIA GPU, you should use one if you can.\n",
    "\n",
    "But what if I told you we could go faster again?\n",
    "\n",
    "You see many modern models can handle batched predictions.\n",
    "\n",
    "This means computing on multiple samples at once.\n",
    "\n",
    "Those are the types of operations where a GPU flourishes!\n",
    "\n",
    "We can perform batched operations by turning our target text samples into a single list and then passing that list to our embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn text chunks into a single list\n",
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 20s\n",
      "Wall time: 15.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0674,  0.0902, -0.0051,  ..., -0.0221, -0.0232,  0.0126],\n",
       "        [ 0.0552,  0.0592, -0.0166,  ..., -0.0120, -0.0103,  0.0227],\n",
       "        [ 0.0280,  0.0340, -0.0206,  ..., -0.0054,  0.0213,  0.0313],\n",
       "        ...,\n",
       "        [ 0.0771,  0.0098, -0.0122,  ..., -0.0409, -0.0752, -0.0241],\n",
       "        [ 0.1030, -0.0165,  0.0083,  ..., -0.0574, -0.0283, -0.0295],\n",
       "        [ 0.0864, -0.0125, -0.0113,  ..., -0.0522, -0.0337, -0.0299]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Embed all texts in batches\n",
    "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32, # you can use different batch sizes here for speed/performance, I found 32 works well for this use case\n",
    "                                               convert_to_tensor=True) # optional to return embeddings as tensor instead of array\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's what I'm talking about!\n",
    "\n",
    "A ~4x improvement (on my GPU) in speed thanks to batched operations.\n",
    "\n",
    "So the tip here is to use a GPU when you can and use batched operations if you can too.\n",
    "\n",
    "Now let's save our chunks and their embeddings so we could import them later if we wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save embeddings to file\n",
    "\n",
    "Since creating embeddings can be a timely process (not so much for our case but it can be for more larger datasets), let's turn our `pages_and_chunks_over_min_token_len` list of dictionaries into a DataFrame and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to file\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can make sure it imports nicely by loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39</td>\n",
       "      <td>Human Nutrition: 2020 Edition UNIVERSITY OF HA...</td>\n",
       "      <td>308</td>\n",
       "      <td>42</td>\n",
       "      <td>77.00</td>\n",
       "      <td>[ 6.74242899e-02  9.02281404e-02 -5.09547861e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "      <td>210</td>\n",
       "      <td>30</td>\n",
       "      <td>52.50</td>\n",
       "      <td>[ 5.52156307e-02  5.92139401e-02 -1.66167300e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-37</td>\n",
       "      <td>Contents Preface University of Hawai‘i at Māno...</td>\n",
       "      <td>766</td>\n",
       "      <td>116</td>\n",
       "      <td>191.50</td>\n",
       "      <td>[ 2.79801954e-02  3.39813679e-02 -2.06426550e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-36</td>\n",
       "      <td>Lifestyles and Nutrition University of Hawai‘i...</td>\n",
       "      <td>941</td>\n",
       "      <td>144</td>\n",
       "      <td>235.25</td>\n",
       "      <td>[ 6.82567060e-02  3.81274708e-02 -8.46855436e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-35</td>\n",
       "      <td>The Cardiovascular System University of Hawai‘...</td>\n",
       "      <td>998</td>\n",
       "      <td>152</td>\n",
       "      <td>249.50</td>\n",
       "      <td>[ 3.30264568e-02 -8.49767309e-03  9.57160536e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0          -39  Human Nutrition: 2020 Edition UNIVERSITY OF HA...   \n",
       "1          -38  Human Nutrition: 2020 Edition by University of...   \n",
       "2          -37  Contents Preface University of Hawai‘i at Māno...   \n",
       "3          -36  Lifestyles and Nutrition University of Hawai‘i...   \n",
       "4          -35  The Cardiovascular System University of Hawai‘...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               308                42              77.00   \n",
       "1               210                30              52.50   \n",
       "2               766               116             191.50   \n",
       "3               941               144             235.25   \n",
       "4               998               152             249.50   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 6.74242899e-02  9.02281404e-02 -5.09547861e-...  \n",
       "1  [ 5.52156307e-02  5.92139401e-02 -1.66167300e-...  \n",
       "2  [ 2.79801954e-02  3.39813679e-02 -2.06426550e-...  \n",
       "3  [ 6.82567060e-02  3.81274708e-02 -8.46855436e-...  \n",
       "4  [ 3.30264568e-02 -8.49767309e-03  9.57160536e-...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import saved file and view\n",
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking and embedding questions\n",
    "\n",
    "> **Which embedding model should I use?**\n",
    "\n",
    "This depends on many factors. My best advice is to experiment, experiment, experiment! \n",
    "\n",
    "If you want the model to run locally, you'll have to make sure it's feasible to run on your own hardware. \n",
    "\n",
    "A good place to see how different models perform on a wide range of embedding tasks is the [Hugging Face Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard).\n",
    "\n",
    "> **What other forms of text chunking/splitting are there?**\n",
    "\n",
    "There are a fair few options here too. We've kept it simple with groups of sentences.\n",
    "\n",
    "For more, [Pinecone has a great guide on different kinds of chunking](https://www.pinecone.io/learn/chunking-strategies/) including for different kinds of data such as markdown and LaTeX.\n",
    "\n",
    "Libraries such as [LangChain also have a good amount of in-built text splitting options](https://python.langchain.com/docs/modules/data_connection/document_transformers/).\n",
    "\n",
    "> **What should I think about when creating my embeddings?**\n",
    "\n",
    "Our model turns text inputs up to 384 tokens long in embedding vectors of size 768.\n",
    "\n",
    "Generally, the larger the vector size, the more information that gets encoded into the embedding (however, this is not always the case, as smaller, better models can outperform larger ones).\n",
    "\n",
    "Though with larger vector sizes comes larger storage and compute requirements.\n",
    "\n",
    "Our model is also relatively small (420MB) in size compared to larger models that are available.\n",
    "\n",
    "Larger models may result in better performance but will also require more compute.\n",
    "\n",
    "So some things to think about:\n",
    "* Size of input - If you need to embed longer sequences, choose a model with a larger input capacity.\n",
    "* Size of embedding vector - Larger is generally a better representation but requires more compute/storage.\n",
    "* Size of model - Larger models generally result in better embeddings but require more compute power/time to run.\n",
    "* Open or closed - Open models allow you to run them on your own hardware whereas closed models can be easier to setup but require an API call to get embeddings.\n",
    "\n",
    "> **Where should I store my embeddings?**\n",
    "\n",
    "If you've got a relatively small dataset, for example, under 100,000 examples (this number is rough and only based on first hand experience), `np.array` or `torch.tensor` can work just fine as your dataset.\n",
    "\n",
    "But if you've got a production system and want to work with 100,000+ embeddings, you may want to look into a [vector database]( https://en.wikipedia.org/wiki/Vector_database) (these have become very popular lately and there are many offerings).\n",
    "\n",
    "### Document Ingestion and Embedding Creation Extensions\n",
    "\n",
    "One major extension to the workflow above would to functionize it.\n",
    "\n",
    "Or turn it into a script.\n",
    "\n",
    "As in, take all the functionality we've created and package it into a single process (e.g. go from document -> embeddings file).\n",
    "\n",
    "So you could input a document on one end and have embeddings come out the other end. The hardest part of this is knowing what kind of preprocessing your text may need before it's turned into embeddings. Cleaner text generally means better results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAG - Search and Answer\n",
    "\n",
    "We discussed RAG briefly in the beginning but let's quickly recap.\n",
    "\n",
    "RAG stands for Retrieval Augmented Generation.\n",
    "\n",
    "Which is another way of saying \"given a query, search for relevant resources and answer based on those resources\".\n",
    "\n",
    "Let's breakdown each step:\n",
    "* **Retrieval** - Get relevant resources given a query. For example, if the query is \"what are the macronutrients?\" the ideal results will contain information about protein, carbohydrates and fats (and possibly alcohol) rather than information about which tractors are the best for farming (though that is also cool information).\n",
    "* **Augmentation** - LLMs are capable of generating text given a prompt. However, this generated text is designed to *look* right. And it often has some correct information, however, they are prone to hallucination (generating a result that *looks* like legit text but is factually wrong). In augmentation, we pass relevant information into the prompt and get an LLM to use that relevant information as the basis of its generation.\n",
    "* **Generation** - This is where the LLM will generate a response that has been flavoured/augmented with the retrieved resources. In turn, this not only gives us a potentially more correct answer, it also gives us resources to investigate more (since we know which resources went into the prompt).\n",
    "\n",
    "The whole idea of RAG is to get an LLM to be more factually correct based on your own input as well as have a reference to where the generated output may have come from.\n",
    "\n",
    "This is an incredibly helpful tool.\n",
    "\n",
    "Let's say you had 1000s of customer support documents.\n",
    "\n",
    "You could use RAG to generate direct answers to questions with links to relevant documentation.\n",
    "\n",
    "Or you were an insurance company with large chains of claims emails.\n",
    "\n",
    "You could use RAG to answer questions about the emails with sources.\n",
    "\n",
    "One helpful analogy is to think of LLMs as calculators for words.\n",
    "\n",
    "With good inputs, the LLM can sort them into helpful outputs.\n",
    "\n",
    "How? \n",
    "\n",
    "It starts with better search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heba-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
